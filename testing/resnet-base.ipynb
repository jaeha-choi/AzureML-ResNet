{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "!pip install -U tensorflow_datasets\n",
    "!apt install -y fonts-nanum fonts-nanum-coding\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAKE = 10\n",
    "BATCH = 32\n",
    "EPOCH = 100\n",
    "REPEATS = 5\n",
    "\n",
    "STRING_CODEC = 'UTF-8'\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "TEXT_LEN = 64\n",
    "TOKEN_LEN = 16\n",
    "LATENT = 256\n",
    "\n",
    "FOLDER_BASE = '/kaggle/input/'\n",
    "FOLDER = FOLDER_BASE+'naver-posts/'\n",
    "FOLDER_IMG = FOLDER + 'img/'\n",
    "FOLDER_SUMMARY = FOLDER + 'summary/'\n",
    "FOLDER_TEXT = FOLDER + 'text/'\n",
    "VOCAB_PATH = FOLDER + 'vocab'\n",
    "\n",
    "FOLDER_W2T2V = FOLDER_BASE+'word2token2vec/'\n",
    "\n",
    "TOKEN_SOS = '<SOS>'\n",
    "TOKEN_EOS = '<EOS>'\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                                         fname='flower_photos', untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
    "                                                     batch_size=BATCH,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = list(CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for n in range(25):\n",
    "      ax = plt.subplot(5,5,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "      plt.axis('off')\n",
    "        \n",
    "image_batch, label_batch = next(train_data_gen)\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    yield from train_data_gen\n",
    "\n",
    "ds = tf.data.Dataset.from_generator(gen, \n",
    "                                   (tf.float32, tf.int64),\n",
    "                                   (tf.TensorShape([None, IMG_HEIGHT, IMG_WIDTH, 3]), tf.TensorShape([None, len(CLASS_NAMES)])))\n",
    "\n",
    "for x in ds.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_img_encoder(img_input, latent_unit):\n",
    "    def res_block(input_layer, filters, downsample=False, name=None):\n",
    "        with tf.name_scope(\"res_block\"):\n",
    "            out = input_layer\n",
    "\n",
    "            if downsample:\n",
    "                out = keras.layers.Conv2D(filters * 4, (3, 3), strides=(2, 2), name=name+\"_downsample\")(out)\n",
    "                input_layer = out\n",
    "                \n",
    "            out = keras.layers.Conv2D(filters, (1, 1), padding='same')(out)\n",
    "            out = keras.layers.BatchNormalization()(out)\n",
    "            out = keras.layers.LeakyReLU(0.2)(out)\n",
    "\n",
    "            out = keras.layers.Conv2D(filters, (3, 3), padding='same')(out)\n",
    "            out = keras.layers.BatchNormalization()(out)\n",
    "            out = keras.layers.LeakyReLU(0.2)(out)\n",
    "\n",
    "            out = keras.layers.Conv2D(filters * 4, (1, 1), padding='same')(out)  \n",
    "            out = keras.layers.BatchNormalization()(out)  \n",
    "\n",
    "            out = out + input_layer\n",
    "            out = keras.layers.LeakyReLU(0.2, name=name+\"_out\")(out)\n",
    "\n",
    "            return out\n",
    "    \n",
    "    img = img_input\n",
    "    \n",
    "    img = keras.layers.Conv2D(64, (7, 7), strides=(2, 2))(img)\n",
    "    img = keras.layers.BatchNormalization()(img)\n",
    "    img = keras.layers.LeakyReLU(0.2)(img)\n",
    "    img = keras.layers.MaxPool2D((3, 3), strides=(2, 2), name=\"pre\")(img)\n",
    "    \n",
    "    img = res_block(img, 64, True, name=\"stg1-d\")\n",
    "    for i in range(2):\n",
    "        img = res_block(img, 64, name=\"stg1-\"+str(i))\n",
    "    \n",
    "    img = res_block(img, 128, True, name=\"stg2-d\")\n",
    "    for i in range(3):\n",
    "        img = res_block(img, 128, name=\"stg2-\"+str(i))\n",
    "\n",
    "    img = res_block(img, 256, True, name=\"stg3-d\")\n",
    "    for i in range(22):\n",
    "        img = res_block(img, 256, name=\"stg3-\"+str(i))\n",
    "    \n",
    "    img = res_block(img, 512, True, name=\"stg4-d\")\n",
    "    for i in range(2):\n",
    "        img = res_block(img, 512, name=\"stg4-\"+str(i))\n",
    "    \n",
    "    img = keras.layers.AveragePooling2D(pool_size=(2, 2), padding='same')(img)\n",
    "    img = keras.layers.Flatten()(img)\n",
    "    img = keras.layers.Dense(latent_unit)(img)\n",
    "    return keras.Model(inputs=[img_input], outputs=[img], name='image_latent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = keras.Input((IMG_HEIGHT, IMG_WIDTH, 3), name='input_img')\n",
    "\n",
    "model_infer = model_img_encoder(input_image, LATENT)\n",
    "model_infer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_latent = model_infer(input_image)\n",
    "\n",
    "classify = keras.layers.Dense(len(CLASS_NAMES), activation='softmax')(img_latent)\n",
    "\n",
    "model_train = keras.Model(inputs=[input_image], outputs=[classify])\n",
    "model_train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint('model_image2vec_train.h5', save_best_only=True)\n",
    "\n",
    "VALID_TAKE = 3\n",
    "ds_validation = ds.take(VALID_TAKE).cache()\n",
    "    \n",
    "model_train.fit(ds.skip(VALID_TAKE).prefetch(TAKE*2).take(TAKE),\n",
    "          validation_data=ds_validation,\n",
    "          epochs=EPOCH,\n",
    "          callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
