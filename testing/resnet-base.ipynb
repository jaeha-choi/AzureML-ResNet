{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n!pip install -U tensorflow_datasets\n!apt install -y fonts-nanum fonts-nanum-coding\n\nimport sys\nimport os\nimport math\n\nimport numpy as np\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom tensorflow import keras\n\nimport pathlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TAKE = 10\nBATCH = 32\nEPOCH = 100\nREPEATS = 5\n\nSTRING_CODEC = 'UTF-8'\n\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nTEXT_LEN = 64\nTOKEN_LEN = 16\nLATENT = 256\n\nFOLDER_BASE = '/kaggle/input/'\nFOLDER = FOLDER_BASE+'naver-posts/'\nFOLDER_IMG = FOLDER + 'img/'\nFOLDER_SUMMARY = FOLDER + 'summary/'\nFOLDER_TEXT = FOLDER + 'text/'\nVOCAB_PATH = FOLDER + 'vocab'\n\nFOLDER_W2T2V = FOLDER_BASE+'word2token2vec/'\n\nTOKEN_SOS = '<SOS>'\nTOKEN_EOS = '<EOS>'\n\n# Any results you write to the current directory are saved as output.\nprint(tf.version.VERSION)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n                                         fname='flower_photos', untar=True)\ndata_dir = pathlib.Path(data_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count = len(list(data_dir.glob('*/*.jpg')))\nimage_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\nCLASS_NAMES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntrain_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n                                                     batch_size=BATCH,\n                                                     shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                     classes = list(CLASS_NAMES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef show_batch(image_batch, label_batch):\n  plt.figure(figsize=(10,10))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n      plt.axis('off')\n        \nimage_batch, label_batch = next(train_data_gen)\nshow_batch(image_batch, label_batch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen():\n    yield from train_data_gen\n\nds = tf.data.Dataset.from_generator(gen, \n                                   (tf.float32, tf.int64),\n                                   (tf.TensorShape([None, IMG_HEIGHT, IMG_WIDTH, 3]), tf.TensorShape([None, len(CLASS_NAMES)])))\n\nfor x in ds.take(1):\n    print(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_img_encoder(img_input, latent_unit):\n    def res_block(input_layer, filters, downsample=False, name=None):\n        with tf.name_scope(\"res_block\"):\n            out = input_layer\n\n            if downsample:\n                out = keras.layers.Conv2D(filters * 4, (3, 3), strides=(2, 2), name=name+\"_downsample\")(out)\n                input_layer = out\n                \n            out = keras.layers.Conv2D(filters, (1, 1), padding='same')(out)\n            out = keras.layers.BatchNormalization()(out)\n            out = keras.layers.LeakyReLU(0.2)(out)\n\n            out = keras.layers.Conv2D(filters, (3, 3), padding='same')(out)\n            out = keras.layers.BatchNormalization()(out)\n            out = keras.layers.LeakyReLU(0.2)(out)\n\n            out = keras.layers.Conv2D(filters * 4, (1, 1), padding='same')(out)  \n            out = keras.layers.BatchNormalization()(out)  \n\n            out = out + input_layer\n            out = keras.layers.LeakyReLU(0.2, name=name+\"_out\")(out)\n\n            return out\n    \n    img = img_input\n    \n    img = keras.layers.Conv2D(64, (7, 7), strides=(2, 2))(img)\n    img = keras.layers.BatchNormalization()(img)\n    img = keras.layers.LeakyReLU(0.2)(img)\n    img = keras.layers.MaxPool2D((3, 3), strides=(2, 2), name=\"pre\")(img)\n    \n    img = res_block(img, 64, True, name=\"stg1-d\")\n    for i in range(2):\n        img = res_block(img, 64, name=\"stg1-\"+str(i))\n    \n    img = res_block(img, 128, True, name=\"stg2-d\")\n    for i in range(3):\n        img = res_block(img, 128, name=\"stg2-\"+str(i))\n\n    img = res_block(img, 256, True, name=\"stg3-d\")\n    for i in range(22):\n        img = res_block(img, 256, name=\"stg3-\"+str(i))\n    \n    img = res_block(img, 512, True, name=\"stg4-d\")\n    for i in range(2):\n        img = res_block(img, 512, name=\"stg4-\"+str(i))\n    \n    img = keras.layers.AveragePooling2D(pool_size=(2, 2), padding='same')(img)\n    img = keras.layers.Flatten()(img)\n    img = keras.layers.Dense(latent_unit)(img)\n    return keras.Model(inputs=[img_input], outputs=[img], name='image_latent')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_image = keras.Input((IMG_HEIGHT, IMG_WIDTH, 3), name='input_img')\n\nmodel_infer = model_img_encoder(input_image, LATENT)\nmodel_infer.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_latent = model_infer(input_image)\n\nclassify = keras.layers.Dense(len(CLASS_NAMES), activation='softmax')(img_latent)\n\nmodel_train = keras.Model(inputs=[input_image], outputs=[classify])\nmodel_train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\nmodel_train.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = keras.callbacks.ModelCheckpoint('model_image2vec_train.h5', save_best_only=True)\n\nVALID_TAKE = 3\nds_validation = ds.take(VALID_TAKE).cache()\n    \nmodel_train.fit(ds.skip(VALID_TAKE).prefetch(TAKE*2).take(TAKE),\n          validation_data=ds_validation,\n          epochs=EPOCH,\n          callbacks=[checkpoint])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}