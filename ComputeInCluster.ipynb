{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Environment\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ],
   "outputs": [],
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1622602949259
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ws = Workspace.from_config()\n",
    "ws"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "Workspace.create(name='ResNet', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='AzureML_UW_ResNet')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1622602949849
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# cluster_name = \"ML-CPU-test\"\n",
    "cluster_name = \"ML-GPU-test\"\n",
    "compute_target = None\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('No compute cluster named {}'.format(cluster_name))\n",
    "    exit()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n"
     ]
    }
   ],
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1622602950336
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "curated_env_name = 'Resnet50v15-CPU-cluster'\n",
    "#pytorch_env = Environment.get(workspace=ws, name=curated_env_name)\n",
    "pytorch_env = Environment.from_conda_specification(name=curated_env_name, file_path='./conda_dependencies.yml')"
   ],
   "outputs": [],
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1622602950492
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.core import Dataset\n",
    "\n",
    "project_folder = './'\n",
    "data_path = 'datasets'\n",
    "\n",
    "datastore = Datastore.get(ws, 'workspaceblobstore')\n",
    "dataset = Dataset.File.from_files(path=(datastore, data_path))\n",
    "data_loc = dataset.as_named_input('input').as_mount()\n",
    "print(data_loc)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.data.dataset_consumption_config.DatasetConsumptionConfig object at 0x0000021BD4F5D5E0>\n"
     ]
    }
   ],
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1622607068637
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "src = ScriptRunConfig(source_directory=project_folder,\n",
    "                        # command=['ls'],\n",
    "                        script='train_resnet.py',\n",
    "                        arguments=[\n",
    "                          '--num_epochs', 16,\n",
    "                          '--batch', '32',\n",
    "                          '--shuffle', 'True',\n",
    "                          '--dataloc', data_loc,\n",
    "                          '--output_dir', './outputs',\n",
    "                        ],\n",
    "                        compute_target=compute_target,\n",
    "                        environment=pytorch_env)\n",
    "\n",
    "run = Experiment(ws, name='Train-Resnet50v15').submit(src)\n",
    "run.wait_for_completion(show_output=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: Train-Resnet50v15_1623560901_ad27fa80\n",
      "Web View: https://ml.azure.com/runs/Train-Resnet50v15_1623560901_ad27fa80?wsid=/subscriptions/92c76a2f-0e1c-4216-b65e-abf7a3f34c1e/resourcegroups/AzureML_UW_ResNet/workspaces/ResNet&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_2e3eade37d74b5feae075ad8f995f1b5c824924c78ab0613ecb43b743132ea7c_p.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-06-13T05:12:17.360686] Entering job preparation.\n",
      "[2021-06-13T05:12:18.083301] Starting job preparation.\n",
      "[2021-06-13T05:12:18.083334] Extracting the control code.\n",
      "[2021-06-13T05:12:18.101680] fetching and extracting the control code on master node.\n",
      "[2021-06-13T05:12:18.101705] Starting extract_project.\n",
      "[2021-06-13T05:12:18.101736] Starting to extract zip file.\n",
      "[2021-06-13T05:12:18.596827] Finished extracting zip file.\n",
      "[2021-06-13T05:12:18.718634] Using urllib.request Python 3.0 or later\n",
      "[2021-06-13T05:12:18.718676] Start fetching snapshots.\n",
      "[2021-06-13T05:12:18.718720] Start fetching snapshot.\n",
      "[2021-06-13T05:12:18.718737] Retrieving project from snapshot: 7d20403d-6e2e-4c30-bd26-7e3bb422633a\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 64\n",
      "[2021-06-13T05:12:21.788461] Finished fetching snapshot.\n",
      "[2021-06-13T05:12:21.788488] Finished fetching snapshots.\n",
      "[2021-06-13T05:12:21.788503] Finished extract_project.\n",
      "[2021-06-13T05:12:21.799022] Finished fetching and extracting the control code.\n",
      "[2021-06-13T05:12:21.805579] Start run_history_prep.\n",
      "[2021-06-13T05:12:21.851022] Job preparation is complete.\n",
      "[2021-06-13T05:12:21.851157] Entering Data Context Managers in Sidecar\n",
      "[2021-06-13T05:12:21.851809] Running Sidecar prep cmd...\n",
      "[2021-06-13T05:12:22.240578] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/resnet/azureml/train-resnet50v15_1623560901_ad27fa80/mounts/workspaceblobstore/azureml/Train-Resnet50v15_1623560901_ad27fa80\n",
      "[2021-06-13T05:12:22.241228] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.28.0 azureml-dataprep==2.16.0. Session id: 80d95765-e850-47d7-80ac-367805830110. Run id: Train-Resnet50v15_1623560901_ad27fa80.\n",
      "Processing 'input'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'datasets')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"74e26162-1324-490a-93fc-cd7aff3a117b\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='ResNet', subscription_id='92c76a2f-0e1c-4216-b65e-abf7a3f34c1e', resource_group='AzureML_UW_ResNet')\"\n",
      "  }\n",
      "}\n",
      "Mounting input to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/resnet/azureml/train-resnet50v15_1623560901_ad27fa80/wd/input_74e26162-1324-490a-93fc-cd7aff3a117b.\n",
      "Mounted input to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/resnet/azureml/train-resnet50v15_1623560901_ad27fa80/wd/input_74e26162-1324-490a-93fc-cd7aff3a117b as folder.\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Set Dataset input's target path to /mnt/batch/tasks/shared/LS_root/jobs/resnet/azureml/train-resnet50v15_1623560901_ad27fa80/wd/input_74e26162-1324-490a-93fc-cd7aff3a117b\n",
      "[2021-06-13T05:12:36.854698] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-06-13T05:12:37.561789] Ran Sidecar prep cmd.\n",
      "[2021-06-13T05:12:37.561884] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "bash: /azureml-envs/azureml_8a0c08d04ee82bb32fbf16e9f6c51e1e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2021/06/13 05:13:14 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/06/13 05:13:14 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "bash: /azureml-envs/azureml_8a0c08d04ee82bb32fbf16e9f6c51e1e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2021/06/13 05:13:14 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "[2021-06-13T05:13:14.833188] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['train_resnet.py', '--num_epochs', '16', '--batch', '32', '--shuffle', 'True', '--dataloc', 'DatasetConsumptionConfig:input', '--output_dir', './outputs'])\n",
      "Script type = None\n",
      "[2021-06-13T05:13:16.156431] Entering Run History Context Manager.\n",
      "[2021-06-13T05:13:16.993373] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/resnet/azureml/train-resnet50v15_1623560901_ad27fa80/mounts/workspaceblobstore/azureml/Train-Resnet50v15_1623560901_ad27fa80\n",
      "[2021-06-13T05:13:16.993645] Preparing to call script [train_resnet.py] with arguments:['--num_epochs', '16', '--batch', '32', '--shuffle', 'True', '--dataloc', '$input', '--output_dir', './outputs']\n",
      "[2021-06-13T05:13:16.993741] After variable expansion, calling script [train_resnet.py] with arguments:['--num_epochs', '16', '--batch', '32', '--shuffle', 'True', '--dataloc', '/mnt/batch/tasks/shared/LS_root/jobs/resnet/azureml/train-resnet50v15_1623560901_ad27fa80/wd/input_74e26162-1324-490a-93fc-cd7aff3a117b', '--output_dir', './outputs']\n",
      "\n",
      "06/13/2021 05:13:19 AM - INFO: Loading dataset from /mnt/batch/tasks/shared/LS_root/jobs/resnet/azureml/train-resnet50v15_1623560901_ad27fa80/wd/input_74e26162-1324-490a-93fc-cd7aff3a117b\n",
      "2021/06/13 05:13:19 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "06/13/2021 05:14:56 AM - INFO: Dataset is ready.\n",
      "06/13/2021 05:14:56 AM - INFO: Preparing model...\n",
      "06/13/2021 05:14:58 AM - INFO: Model is ready.\n",
      "06/13/2021 05:14:58 AM - INFO: Setting hyperparameters...\n",
      "06/13/2021 05:14:58 AM - INFO: Ready for training.\n",
      "06/13/2021 05:14:58 AM - INFO: Epoch: 1\n",
      "06/13/2021 05:15:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 5/3125\t\tLoss: 5.349295616149902\n",
      "06/13/2021 05:15:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 10/3125\t\tLoss: 5.395599365234375\n",
      "06/13/2021 05:15:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 15/3125\t\tLoss: 5.478743553161621\n",
      "06/13/2021 05:15:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 20/3125\t\tLoss: 5.450273036956787\n",
      "06/13/2021 05:15:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 25/3125\t\tLoss: 5.330013275146484\n",
      "06/13/2021 05:16:03 AM - INFO: Training:: Epoch: 1/16\tBatch: 30/3125\t\tLoss: 5.48007869720459\n",
      "06/13/2021 05:16:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 35/3125\t\tLoss: 5.400668144226074\n",
      "06/13/2021 05:16:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 40/3125\t\tLoss: 5.276220798492432\n",
      "06/13/2021 05:16:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 45/3125\t\tLoss: 5.355449676513672\n",
      "06/13/2021 05:16:42 AM - INFO: Training:: Epoch: 1/16\tBatch: 50/3125\t\tLoss: 5.428852558135986\n",
      "06/13/2021 05:16:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 55/3125\t\tLoss: 5.356385231018066\n",
      "06/13/2021 05:17:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 60/3125\t\tLoss: 5.348897457122803\n",
      "06/13/2021 05:17:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 65/3125\t\tLoss: 5.268176078796387\n",
      "06/13/2021 05:17:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 70/3125\t\tLoss: 5.351288318634033\n",
      "06/13/2021 05:17:30 AM - INFO: Training:: Epoch: 1/16\tBatch: 75/3125\t\tLoss: 5.224677562713623\n",
      "06/13/2021 05:17:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 80/3125\t\tLoss: 5.354363441467285\n",
      "06/13/2021 05:17:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 85/3125\t\tLoss: 5.376785755157471\n",
      "06/13/2021 05:17:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 90/3125\t\tLoss: 5.172102451324463\n",
      "06/13/2021 05:18:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 95/3125\t\tLoss: 5.331691265106201\n",
      "06/13/2021 05:18:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 100/3125\t\tLoss: 5.171419143676758\n",
      "06/13/2021 05:18:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 105/3125\t\tLoss: 5.464709281921387\n",
      "06/13/2021 05:18:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 110/3125\t\tLoss: 5.407146453857422\n",
      "06/13/2021 05:18:50 AM - INFO: Training:: Epoch: 1/16\tBatch: 115/3125\t\tLoss: 5.551382541656494\n",
      "06/13/2021 05:19:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 120/3125\t\tLoss: 5.350533962249756\n",
      "06/13/2021 05:19:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 125/3125\t\tLoss: 5.2351884841918945\n",
      "06/13/2021 05:19:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 130/3125\t\tLoss: 5.573338508605957\n",
      "06/13/2021 05:19:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 135/3125\t\tLoss: 5.249181270599365\n",
      "06/13/2021 05:19:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 140/3125\t\tLoss: 5.3413872718811035\n",
      "06/13/2021 05:19:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 145/3125\t\tLoss: 5.396934509277344\n",
      "06/13/2021 05:19:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 150/3125\t\tLoss: 5.545487880706787\n",
      "06/13/2021 05:20:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 155/3125\t\tLoss: 5.546618938446045\n",
      "06/13/2021 05:20:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 160/3125\t\tLoss: 5.324334621429443\n",
      "06/13/2021 05:20:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 165/3125\t\tLoss: 5.294509410858154\n",
      "06/13/2021 05:20:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 170/3125\t\tLoss: 5.273634910583496\n",
      "06/13/2021 05:20:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 175/3125\t\tLoss: 5.30389928817749\n",
      "06/13/2021 05:20:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 180/3125\t\tLoss: 5.438868522644043\n",
      "06/13/2021 05:21:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 185/3125\t\tLoss: 5.46619176864624\n",
      "06/13/2021 05:21:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 190/3125\t\tLoss: 5.043425559997559\n",
      "06/13/2021 05:21:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 195/3125\t\tLoss: 5.312602519989014\n",
      "06/13/2021 05:21:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 200/3125\t\tLoss: 5.070675849914551\n",
      "06/13/2021 05:21:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 205/3125\t\tLoss: 5.125986099243164\n",
      "06/13/2021 05:21:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 210/3125\t\tLoss: 5.151583671569824\n",
      "06/13/2021 05:22:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 215/3125\t\tLoss: 5.21018648147583\n",
      "06/13/2021 05:22:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 220/3125\t\tLoss: 5.021326541900635\n",
      "06/13/2021 05:22:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 225/3125\t\tLoss: 5.256568431854248\n",
      "06/13/2021 05:22:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 230/3125\t\tLoss: 5.225633144378662\n",
      "06/13/2021 05:22:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 235/3125\t\tLoss: 5.18364143371582\n",
      "06/13/2021 05:22:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 240/3125\t\tLoss: 5.296445369720459\n",
      "06/13/2021 05:23:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 245/3125\t\tLoss: 5.181146621704102\n",
      "06/13/2021 05:23:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 250/3125\t\tLoss: 5.33048152923584\n",
      "06/13/2021 05:23:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 255/3125\t\tLoss: 5.31001091003418\n",
      "06/13/2021 05:23:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 260/3125\t\tLoss: 5.274455547332764\n",
      "06/13/2021 05:23:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 265/3125\t\tLoss: 5.381312847137451\n",
      "06/13/2021 05:23:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 270/3125\t\tLoss: 5.358492851257324\n",
      "06/13/2021 05:24:10 AM - INFO: Training:: Epoch: 1/16\tBatch: 275/3125\t\tLoss: 5.0919647216796875\n",
      "06/13/2021 05:24:20 AM - INFO: Training:: Epoch: 1/16\tBatch: 280/3125\t\tLoss: 5.195285797119141\n",
      "06/13/2021 05:24:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 285/3125\t\tLoss: 5.171707630157471\n",
      "06/13/2021 05:24:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 290/3125\t\tLoss: 5.1622138023376465\n",
      "06/13/2021 05:24:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 295/3125\t\tLoss: 5.208925247192383\n",
      "06/13/2021 05:24:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 300/3125\t\tLoss: 5.243558883666992\n",
      "06/13/2021 05:25:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 305/3125\t\tLoss: 5.109293460845947\n",
      "06/13/2021 05:25:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 310/3125\t\tLoss: 5.036181926727295\n",
      "06/13/2021 05:25:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 315/3125\t\tLoss: 5.2676591873168945\n",
      "06/13/2021 05:25:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 320/3125\t\tLoss: 5.21535587310791\n",
      "06/13/2021 05:25:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 325/3125\t\tLoss: 5.048263072967529\n",
      "06/13/2021 05:25:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 330/3125\t\tLoss: 5.089489459991455\n",
      "06/13/2021 05:26:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 335/3125\t\tLoss: 5.284805774688721\n",
      "06/13/2021 05:26:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 340/3125\t\tLoss: 5.076044082641602\n",
      "06/13/2021 05:26:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 345/3125\t\tLoss: 5.193673133850098\n",
      "06/13/2021 05:26:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 350/3125\t\tLoss: 5.2178239822387695\n",
      "06/13/2021 05:26:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 355/3125\t\tLoss: 4.905610084533691\n",
      "06/13/2021 05:26:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 360/3125\t\tLoss: 5.244441032409668\n",
      "06/13/2021 05:27:05 AM - INFO: Training:: Epoch: 1/16\tBatch: 365/3125\t\tLoss: 5.086079120635986\n",
      "06/13/2021 05:27:15 AM - INFO: Training:: Epoch: 1/16\tBatch: 370/3125\t\tLoss: 5.290314197540283\n",
      "06/13/2021 05:27:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 375/3125\t\tLoss: 4.924744606018066\n",
      "06/13/2021 05:27:35 AM - INFO: Training:: Epoch: 1/16\tBatch: 380/3125\t\tLoss: 5.184013843536377\n",
      "06/13/2021 05:27:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 385/3125\t\tLoss: 5.094820022583008\n",
      "06/13/2021 05:27:54 AM - INFO: Training:: Epoch: 1/16\tBatch: 390/3125\t\tLoss: 5.288148403167725\n",
      "06/13/2021 05:28:04 AM - INFO: Training:: Epoch: 1/16\tBatch: 395/3125\t\tLoss: 5.175286769866943\n",
      "06/13/2021 05:28:15 AM - INFO: Training:: Epoch: 1/16\tBatch: 400/3125\t\tLoss: 5.143341064453125\n",
      "06/13/2021 05:28:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 405/3125\t\tLoss: 5.206917762756348\n",
      "06/13/2021 05:28:35 AM - INFO: Training:: Epoch: 1/16\tBatch: 410/3125\t\tLoss: 5.262027740478516\n",
      "06/13/2021 05:28:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 415/3125\t\tLoss: 5.044615268707275\n",
      "06/13/2021 05:28:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 420/3125\t\tLoss: 5.370092868804932\n",
      "06/13/2021 05:29:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 425/3125\t\tLoss: 5.050673484802246\n",
      "06/13/2021 05:29:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 430/3125\t\tLoss: 5.2193498611450195\n",
      "06/13/2021 05:29:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 435/3125\t\tLoss: 4.977482318878174\n",
      "06/13/2021 05:29:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 440/3125\t\tLoss: 5.14654541015625\n",
      "06/13/2021 05:29:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 445/3125\t\tLoss: 5.2588348388671875\n",
      "06/13/2021 05:29:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 450/3125\t\tLoss: 5.027981281280518\n",
      "06/13/2021 05:30:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 455/3125\t\tLoss: 5.132880210876465\n",
      "06/13/2021 05:30:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 460/3125\t\tLoss: 5.147911548614502\n",
      "06/13/2021 05:30:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 465/3125\t\tLoss: 5.040594577789307\n",
      "06/13/2021 05:30:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 470/3125\t\tLoss: 5.099056243896484\n",
      "06/13/2021 05:30:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 475/3125\t\tLoss: 4.989784240722656\n",
      "06/13/2021 05:30:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 480/3125\t\tLoss: 5.155783653259277\n",
      "06/13/2021 05:31:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 485/3125\t\tLoss: 5.044837951660156\n",
      "06/13/2021 05:31:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 490/3125\t\tLoss: 4.953283786773682\n",
      "06/13/2021 05:31:30 AM - INFO: Training:: Epoch: 1/16\tBatch: 495/3125\t\tLoss: 4.937480926513672\n",
      "06/13/2021 05:31:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 500/3125\t\tLoss: 4.9904866218566895\n",
      "06/13/2021 05:31:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 505/3125\t\tLoss: 5.211116313934326\n",
      "06/13/2021 05:32:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 510/3125\t\tLoss: 4.985933780670166\n",
      "06/13/2021 05:32:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 515/3125\t\tLoss: 5.191702365875244\n",
      "06/13/2021 05:32:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 520/3125\t\tLoss: 4.975045204162598\n",
      "06/13/2021 05:32:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 525/3125\t\tLoss: 5.051995277404785\n",
      "06/13/2021 05:32:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 530/3125\t\tLoss: 4.970240592956543\n",
      "06/13/2021 05:32:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 535/3125\t\tLoss: 5.039492130279541\n",
      "06/13/2021 05:33:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 540/3125\t\tLoss: 5.127686500549316\n",
      "06/13/2021 05:33:15 AM - INFO: Training:: Epoch: 1/16\tBatch: 545/3125\t\tLoss: 5.000298023223877\n",
      "06/13/2021 05:33:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 550/3125\t\tLoss: 4.755080699920654\n",
      "06/13/2021 05:33:35 AM - INFO: Training:: Epoch: 1/16\tBatch: 555/3125\t\tLoss: 5.2526350021362305\n",
      "06/13/2021 05:33:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 560/3125\t\tLoss: 5.354721546173096\n",
      "06/13/2021 05:33:54 AM - INFO: Training:: Epoch: 1/16\tBatch: 565/3125\t\tLoss: 4.869197368621826\n",
      "06/13/2021 05:34:04 AM - INFO: Training:: Epoch: 1/16\tBatch: 570/3125\t\tLoss: 5.134533405303955\n",
      "06/13/2021 05:34:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 575/3125\t\tLoss: 4.86043643951416\n",
      "06/13/2021 05:34:24 AM - INFO: Training:: Epoch: 1/16\tBatch: 580/3125\t\tLoss: 5.21611213684082\n",
      "06/13/2021 05:34:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 585/3125\t\tLoss: 4.811526298522949\n",
      "06/13/2021 05:34:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 590/3125\t\tLoss: 5.141862392425537\n",
      "06/13/2021 05:34:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 595/3125\t\tLoss: 5.138247489929199\n",
      "06/13/2021 05:35:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 600/3125\t\tLoss: 5.356131553649902\n",
      "06/13/2021 05:35:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 605/3125\t\tLoss: 5.031040668487549\n",
      "06/13/2021 05:35:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 610/3125\t\tLoss: 4.936182022094727\n",
      "06/13/2021 05:35:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 615/3125\t\tLoss: 5.209303855895996\n",
      "06/13/2021 05:35:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 620/3125\t\tLoss: 4.956789016723633\n",
      "06/13/2021 05:35:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 625/3125\t\tLoss: 5.11978816986084\n",
      "06/13/2021 05:35:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 630/3125\t\tLoss: 5.0375823974609375\n",
      "06/13/2021 05:36:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 635/3125\t\tLoss: 4.88528299331665\n",
      "06/13/2021 05:36:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 640/3125\t\tLoss: 5.054590225219727\n",
      "06/13/2021 05:36:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 645/3125\t\tLoss: 4.924454689025879\n",
      "06/13/2021 05:36:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 650/3125\t\tLoss: 5.024702072143555\n",
      "06/13/2021 05:36:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 655/3125\t\tLoss: 4.953249454498291\n",
      "06/13/2021 05:36:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 660/3125\t\tLoss: 5.227499485015869\n",
      "06/13/2021 05:37:05 AM - INFO: Training:: Epoch: 1/16\tBatch: 665/3125\t\tLoss: 4.943515300750732\n",
      "06/13/2021 05:37:14 AM - INFO: Training:: Epoch: 1/16\tBatch: 670/3125\t\tLoss: 5.186004638671875\n",
      "06/13/2021 05:37:24 AM - INFO: Training:: Epoch: 1/16\tBatch: 675/3125\t\tLoss: 5.129123687744141\n",
      "06/13/2021 05:37:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 680/3125\t\tLoss: 5.026190280914307\n",
      "06/13/2021 05:37:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 685/3125\t\tLoss: 4.764800071716309\n",
      "06/13/2021 05:37:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 690/3125\t\tLoss: 4.711874008178711\n",
      "06/13/2021 05:38:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 695/3125\t\tLoss: 4.86192512512207\n",
      "06/13/2021 05:38:14 AM - INFO: Training:: Epoch: 1/16\tBatch: 700/3125\t\tLoss: 4.9845051765441895\n",
      "06/13/2021 05:38:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 705/3125\t\tLoss: 5.2496337890625\n",
      "06/13/2021 05:38:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 710/3125\t\tLoss: 4.925172805786133\n",
      "06/13/2021 05:38:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 715/3125\t\tLoss: 5.194239139556885\n",
      "06/13/2021 05:38:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 720/3125\t\tLoss: 4.646839618682861\n",
      "06/13/2021 05:39:03 AM - INFO: Training:: Epoch: 1/16\tBatch: 725/3125\t\tLoss: 5.062532424926758\n",
      "06/13/2021 05:39:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 730/3125\t\tLoss: 4.8362932205200195\n",
      "06/13/2021 05:39:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 735/3125\t\tLoss: 5.096124649047852\n",
      "06/13/2021 05:39:32 AM - INFO: Training:: Epoch: 1/16\tBatch: 740/3125\t\tLoss: 4.939685344696045\n",
      "06/13/2021 05:39:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 745/3125\t\tLoss: 4.805143356323242\n",
      "06/13/2021 05:39:50 AM - INFO: Training:: Epoch: 1/16\tBatch: 750/3125\t\tLoss: 4.75437593460083\n",
      "06/13/2021 05:40:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 755/3125\t\tLoss: 5.001499176025391\n",
      "06/13/2021 05:40:10 AM - INFO: Training:: Epoch: 1/16\tBatch: 760/3125\t\tLoss: 4.972682952880859\n",
      "06/13/2021 05:40:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 765/3125\t\tLoss: 4.763517379760742\n",
      "06/13/2021 05:40:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 770/3125\t\tLoss: 4.874573707580566\n",
      "06/13/2021 05:40:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 775/3125\t\tLoss: 5.186391353607178\n",
      "06/13/2021 05:40:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 780/3125\t\tLoss: 5.038205623626709\n",
      "06/13/2021 05:40:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 785/3125\t\tLoss: 5.156857967376709\n",
      "06/13/2021 05:41:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 790/3125\t\tLoss: 4.900100231170654\n",
      "06/13/2021 05:41:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 795/3125\t\tLoss: 4.91904878616333\n",
      "06/13/2021 05:41:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 800/3125\t\tLoss: 4.730699062347412\n",
      "06/13/2021 05:41:35 AM - INFO: Training:: Epoch: 1/16\tBatch: 805/3125\t\tLoss: 5.255039215087891\n",
      "06/13/2021 05:41:44 AM - INFO: Training:: Epoch: 1/16\tBatch: 810/3125\t\tLoss: 5.050741672515869\n",
      "06/13/2021 05:41:54 AM - INFO: Training:: Epoch: 1/16\tBatch: 815/3125\t\tLoss: 5.019599437713623\n",
      "06/13/2021 05:42:04 AM - INFO: Training:: Epoch: 1/16\tBatch: 820/3125\t\tLoss: 4.9012041091918945\n",
      "06/13/2021 05:42:14 AM - INFO: Training:: Epoch: 1/16\tBatch: 825/3125\t\tLoss: 4.821262359619141\n",
      "06/13/2021 05:42:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 830/3125\t\tLoss: 5.035377502441406\n",
      "06/13/2021 05:42:34 AM - INFO: Training:: Epoch: 1/16\tBatch: 835/3125\t\tLoss: 4.811265468597412\n",
      "06/13/2021 05:42:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 840/3125\t\tLoss: 4.982522010803223\n",
      "06/13/2021 05:42:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 845/3125\t\tLoss: 5.00014591217041\n",
      "06/13/2021 05:43:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 850/3125\t\tLoss: 4.873734474182129\n",
      "06/13/2021 05:43:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 855/3125\t\tLoss: 5.101264953613281\n",
      "06/13/2021 05:43:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 860/3125\t\tLoss: 4.973604202270508\n",
      "06/13/2021 05:43:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 865/3125\t\tLoss: 4.7504777908325195\n",
      "06/13/2021 05:43:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 870/3125\t\tLoss: 5.068312168121338\n",
      "06/13/2021 05:43:50 AM - INFO: Training:: Epoch: 1/16\tBatch: 875/3125\t\tLoss: 4.965342998504639\n",
      "06/13/2021 05:43:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 880/3125\t\tLoss: 4.953210830688477\n",
      "06/13/2021 05:44:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 885/3125\t\tLoss: 5.030666828155518\n",
      "06/13/2021 05:44:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 890/3125\t\tLoss: 4.731860637664795\n",
      "06/13/2021 05:44:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 895/3125\t\tLoss: 4.9434895515441895\n",
      "06/13/2021 05:44:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 900/3125\t\tLoss: 4.835007667541504\n",
      "06/13/2021 05:44:47 AM - INFO: Training:: Epoch: 1/16\tBatch: 905/3125\t\tLoss: 4.865603923797607\n",
      "06/13/2021 05:44:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 910/3125\t\tLoss: 4.677621841430664\n",
      "06/13/2021 05:45:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 915/3125\t\tLoss: 4.692482948303223\n",
      "06/13/2021 05:45:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 920/3125\t\tLoss: 4.705406665802002\n",
      "06/13/2021 05:45:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 925/3125\t\tLoss: 4.702724456787109\n",
      "06/13/2021 05:45:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 930/3125\t\tLoss: 4.915291786193848\n",
      "06/13/2021 05:45:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 935/3125\t\tLoss: 4.879563808441162\n",
      "06/13/2021 05:45:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 940/3125\t\tLoss: 4.843923091888428\n",
      "06/13/2021 05:46:05 AM - INFO: Training:: Epoch: 1/16\tBatch: 945/3125\t\tLoss: 4.982843399047852\n",
      "06/13/2021 05:46:14 AM - INFO: Training:: Epoch: 1/16\tBatch: 950/3125\t\tLoss: 4.783787250518799\n",
      "06/13/2021 05:46:24 AM - INFO: Training:: Epoch: 1/16\tBatch: 955/3125\t\tLoss: 4.834537506103516\n",
      "06/13/2021 05:46:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 960/3125\t\tLoss: 4.828409194946289\n",
      "06/13/2021 05:46:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 965/3125\t\tLoss: 4.965206623077393\n",
      "06/13/2021 05:46:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 970/3125\t\tLoss: 4.908888816833496\n",
      "06/13/2021 05:47:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 975/3125\t\tLoss: 4.861216068267822\n",
      "06/13/2021 05:47:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 980/3125\t\tLoss: 4.9725236892700195\n",
      "06/13/2021 05:47:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 985/3125\t\tLoss: 4.987343788146973\n",
      "06/13/2021 05:47:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 990/3125\t\tLoss: 4.935213088989258\n",
      "06/13/2021 05:47:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 995/3125\t\tLoss: 4.786486625671387\n",
      "06/13/2021 05:47:50 AM - INFO: Training:: Epoch: 1/16\tBatch: 1000/3125\t\tLoss: 4.723960876464844\n",
      "06/13/2021 05:48:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 1005/3125\t\tLoss: 4.993198871612549\n",
      "06/13/2021 05:48:10 AM - INFO: Training:: Epoch: 1/16\tBatch: 1010/3125\t\tLoss: 5.0619120597839355\n",
      "06/13/2021 05:48:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 1015/3125\t\tLoss: 4.571281433105469\n",
      "06/13/2021 05:48:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 1020/3125\t\tLoss: 4.554427623748779\n",
      "06/13/2021 05:48:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 1025/3125\t\tLoss: 5.012458324432373\n",
      "06/13/2021 05:48:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 1030/3125\t\tLoss: 4.829263687133789\n",
      "06/13/2021 05:48:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 1035/3125\t\tLoss: 4.680032730102539\n",
      "06/13/2021 05:49:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 1040/3125\t\tLoss: 4.7831244468688965\n",
      "06/13/2021 05:49:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 1045/3125\t\tLoss: 5.140461444854736\n",
      "06/13/2021 05:49:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 1050/3125\t\tLoss: 4.700345039367676\n",
      "06/13/2021 05:49:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 1055/3125\t\tLoss: 5.056380748748779\n",
      "06/13/2021 05:49:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 1060/3125\t\tLoss: 4.55972146987915\n",
      "06/13/2021 05:49:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 1065/3125\t\tLoss: 4.899867057800293\n",
      "06/13/2021 05:50:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 1070/3125\t\tLoss: 4.660444259643555\n",
      "06/13/2021 05:50:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 1075/3125\t\tLoss: 5.0357584953308105\n",
      "06/13/2021 05:50:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 1080/3125\t\tLoss: 4.886771202087402\n",
      "06/13/2021 05:50:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 1085/3125\t\tLoss: 4.7184882164001465\n",
      "06/13/2021 05:50:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 1090/3125\t\tLoss: 4.981187343597412\n",
      "06/13/2021 05:50:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 1095/3125\t\tLoss: 4.705463409423828\n",
      "06/13/2021 05:51:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 1100/3125\t\tLoss: 5.071549892425537\n",
      "06/13/2021 05:51:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 1105/3125\t\tLoss: 4.835930347442627\n",
      "06/13/2021 05:51:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 1110/3125\t\tLoss: 4.8232340812683105\n",
      "06/13/2021 05:51:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 1115/3125\t\tLoss: 4.568851947784424\n",
      "06/13/2021 05:51:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 1120/3125\t\tLoss: 4.652916431427002\n",
      "06/13/2021 05:51:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 1125/3125\t\tLoss: 5.086462020874023\n",
      "06/13/2021 05:52:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 1130/3125\t\tLoss: 5.149290561676025\n",
      "06/13/2021 05:52:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 1135/3125\t\tLoss: 4.722736358642578\n",
      "06/13/2021 05:52:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 1140/3125\t\tLoss: 4.675500869750977\n",
      "06/13/2021 05:52:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 1145/3125\t\tLoss: 5.001783847808838\n",
      "06/13/2021 05:52:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 1150/3125\t\tLoss: 4.669130802154541\n",
      "06/13/2021 05:52:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 1155/3125\t\tLoss: 4.624699592590332\n",
      "06/13/2021 05:53:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 1160/3125\t\tLoss: 4.868368148803711\n",
      "06/13/2021 05:53:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 1165/3125\t\tLoss: 4.543906211853027\n",
      "06/13/2021 05:53:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 1170/3125\t\tLoss: 5.104986190795898\n",
      "06/13/2021 05:53:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 1175/3125\t\tLoss: 4.740361213684082\n",
      "06/13/2021 05:53:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 1180/3125\t\tLoss: 4.723703384399414\n",
      "06/13/2021 05:53:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 1185/3125\t\tLoss: 4.733172416687012\n",
      "06/13/2021 05:54:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 1190/3125\t\tLoss: 4.562519550323486\n",
      "06/13/2021 05:54:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 1195/3125\t\tLoss: 4.573700428009033\n",
      "06/13/2021 05:54:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 1200/3125\t\tLoss: 4.632882595062256\n",
      "06/13/2021 05:54:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 1205/3125\t\tLoss: 4.623903274536133\n",
      "06/13/2021 05:54:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 1210/3125\t\tLoss: 4.9038543701171875\n",
      "06/13/2021 05:54:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 1215/3125\t\tLoss: 4.686017990112305\n",
      "06/13/2021 05:55:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 1220/3125\t\tLoss: 4.667598724365234\n",
      "06/13/2021 05:55:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 1225/3125\t\tLoss: 4.31826114654541\n",
      "06/13/2021 05:55:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 1230/3125\t\tLoss: 4.81959342956543\n",
      "06/13/2021 05:55:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 1235/3125\t\tLoss: 4.897448539733887\n",
      "06/13/2021 05:55:47 AM - INFO: Training:: Epoch: 1/16\tBatch: 1240/3125\t\tLoss: 5.145859241485596\n",
      "06/13/2021 05:55:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 1245/3125\t\tLoss: 4.847364902496338\n",
      "06/13/2021 05:56:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 1250/3125\t\tLoss: 5.020435333251953\n",
      "06/13/2021 05:56:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 1255/3125\t\tLoss: 4.768938064575195\n",
      "06/13/2021 05:56:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 1260/3125\t\tLoss: 4.562617301940918\n",
      "06/13/2021 05:56:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 1265/3125\t\tLoss: 4.953258514404297\n",
      "06/13/2021 05:56:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 1270/3125\t\tLoss: 4.910478115081787\n",
      "06/13/2021 05:56:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 1275/3125\t\tLoss: 4.532411098480225\n",
      "06/13/2021 05:57:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 1280/3125\t\tLoss: 4.468679428100586\n",
      "06/13/2021 05:57:15 AM - INFO: Training:: Epoch: 1/16\tBatch: 1285/3125\t\tLoss: 4.653964519500732\n",
      "06/13/2021 05:57:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 1290/3125\t\tLoss: 4.879943370819092\n",
      "06/13/2021 05:57:35 AM - INFO: Training:: Epoch: 1/16\tBatch: 1295/3125\t\tLoss: 4.772097110748291\n",
      "06/13/2021 05:57:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 1300/3125\t\tLoss: 4.61842155456543\n",
      "06/13/2021 05:57:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 1305/3125\t\tLoss: 4.847243785858154\n",
      "06/13/2021 05:58:05 AM - INFO: Training:: Epoch: 1/16\tBatch: 1310/3125\t\tLoss: 4.8492655754089355\n",
      "06/13/2021 05:58:14 AM - INFO: Training:: Epoch: 1/16\tBatch: 1315/3125\t\tLoss: 4.5001444816589355\n",
      "06/13/2021 05:58:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 1320/3125\t\tLoss: 5.2291083335876465\n",
      "06/13/2021 05:58:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 1325/3125\t\tLoss: 4.548201084136963\n",
      "06/13/2021 05:58:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 1330/3125\t\tLoss: 4.985221862792969\n",
      "06/13/2021 05:58:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 1335/3125\t\tLoss: 4.551271915435791\n",
      "06/13/2021 05:59:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 1340/3125\t\tLoss: 4.787386894226074\n",
      "06/13/2021 05:59:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 1345/3125\t\tLoss: 4.6419525146484375\n",
      "06/13/2021 05:59:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 1350/3125\t\tLoss: 4.683944225311279\n",
      "06/13/2021 05:59:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 1355/3125\t\tLoss: 4.64389705657959\n",
      "06/13/2021 05:59:47 AM - INFO: Training:: Epoch: 1/16\tBatch: 1360/3125\t\tLoss: 4.834728240966797\n",
      "06/13/2021 05:59:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 1365/3125\t\tLoss: 4.507580280303955\n",
      "06/13/2021 06:00:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 1370/3125\t\tLoss: 4.561494827270508\n",
      "06/13/2021 06:00:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 1375/3125\t\tLoss: 4.863784313201904\n",
      "06/13/2021 06:00:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 1380/3125\t\tLoss: 4.747429370880127\n",
      "06/13/2021 06:00:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 1385/3125\t\tLoss: 4.729764461517334\n",
      "06/13/2021 06:00:47 AM - INFO: Training:: Epoch: 1/16\tBatch: 1390/3125\t\tLoss: 4.68770694732666\n",
      "06/13/2021 06:00:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 1395/3125\t\tLoss: 4.746505260467529\n",
      "06/13/2021 06:01:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 1400/3125\t\tLoss: 4.752554893493652\n",
      "06/13/2021 06:01:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 1405/3125\t\tLoss: 4.436215877532959\n",
      "06/13/2021 06:01:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 1410/3125\t\tLoss: 4.38942289352417\n",
      "06/13/2021 06:01:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 1415/3125\t\tLoss: 4.55210542678833\n",
      "06/13/2021 06:01:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 1420/3125\t\tLoss: 4.55674409866333\n",
      "06/13/2021 06:02:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 1425/3125\t\tLoss: 4.443341255187988\n",
      "06/13/2021 06:02:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 1430/3125\t\tLoss: 4.54195499420166\n",
      "06/13/2021 06:02:22 AM - INFO: Training:: Epoch: 1/16\tBatch: 1435/3125\t\tLoss: 4.160712242126465\n",
      "06/13/2021 06:02:32 AM - INFO: Training:: Epoch: 1/16\tBatch: 1440/3125\t\tLoss: 5.157058238983154\n",
      "06/13/2021 06:02:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 1445/3125\t\tLoss: 4.453551769256592\n",
      "06/13/2021 06:02:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 1450/3125\t\tLoss: 4.888193607330322\n",
      "06/13/2021 06:03:03 AM - INFO: Training:: Epoch: 1/16\tBatch: 1455/3125\t\tLoss: 4.5044965744018555\n",
      "06/13/2021 06:03:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 1460/3125\t\tLoss: 4.595200061798096\n",
      "06/13/2021 06:03:24 AM - INFO: Training:: Epoch: 1/16\tBatch: 1465/3125\t\tLoss: 4.852709770202637\n",
      "06/13/2021 06:03:34 AM - INFO: Training:: Epoch: 1/16\tBatch: 1470/3125\t\tLoss: 4.487701416015625\n",
      "06/13/2021 06:03:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 1475/3125\t\tLoss: 4.39277982711792\n",
      "06/13/2021 06:03:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 1480/3125\t\tLoss: 4.851751804351807\n",
      "06/13/2021 06:04:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 1485/3125\t\tLoss: 4.739650249481201\n",
      "06/13/2021 06:04:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 1490/3125\t\tLoss: 4.584654808044434\n",
      "06/13/2021 06:04:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 1495/3125\t\tLoss: 4.486367225646973\n",
      "06/13/2021 06:04:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 1500/3125\t\tLoss: 4.7970194816589355\n",
      "06/13/2021 06:04:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 1505/3125\t\tLoss: 4.2997589111328125\n",
      "06/13/2021 06:04:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 1510/3125\t\tLoss: 4.833550453186035\n",
      "06/13/2021 06:05:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 1515/3125\t\tLoss: 4.8168721199035645\n",
      "06/13/2021 06:05:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 1520/3125\t\tLoss: 4.537884712219238\n",
      "06/13/2021 06:05:30 AM - INFO: Training:: Epoch: 1/16\tBatch: 1525/3125\t\tLoss: 5.0476837158203125\n",
      "06/13/2021 06:05:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 1530/3125\t\tLoss: 4.410240173339844\n",
      "06/13/2021 06:05:50 AM - INFO: Training:: Epoch: 1/16\tBatch: 1535/3125\t\tLoss: 4.485339641571045\n",
      "06/13/2021 06:06:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 1540/3125\t\tLoss: 4.383747577667236\n",
      "06/13/2021 06:06:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 1545/3125\t\tLoss: 4.670605659484863\n",
      "06/13/2021 06:06:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 1550/3125\t\tLoss: 4.3709869384765625\n",
      "06/13/2021 06:06:34 AM - INFO: Training:: Epoch: 1/16\tBatch: 1555/3125\t\tLoss: 4.519504070281982\n",
      "06/13/2021 06:06:44 AM - INFO: Training:: Epoch: 1/16\tBatch: 1560/3125\t\tLoss: 4.758053779602051\n",
      "06/13/2021 06:06:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 1565/3125\t\tLoss: 4.63787841796875\n",
      "06/13/2021 06:07:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 1570/3125\t\tLoss: 4.517058849334717\n",
      "06/13/2021 06:07:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 1575/3125\t\tLoss: 4.508206844329834\n",
      "06/13/2021 06:07:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 1580/3125\t\tLoss: 4.4202375411987305\n",
      "06/13/2021 06:07:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 1585/3125\t\tLoss: 4.4013566970825195\n",
      "06/13/2021 06:07:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 1590/3125\t\tLoss: 4.63496208190918\n",
      "06/13/2021 06:08:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 1595/3125\t\tLoss: 4.898678302764893\n",
      "06/13/2021 06:08:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 1600/3125\t\tLoss: 4.61680269241333\n",
      "06/13/2021 06:08:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 1605/3125\t\tLoss: 4.737151145935059\n",
      "06/13/2021 06:08:34 AM - INFO: Training:: Epoch: 1/16\tBatch: 1610/3125\t\tLoss: 4.2414937019348145\n",
      "06/13/2021 06:08:44 AM - INFO: Training:: Epoch: 1/16\tBatch: 1615/3125\t\tLoss: 4.698529243469238\n",
      "06/13/2021 06:08:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 1620/3125\t\tLoss: 4.7157721519470215\n",
      "06/13/2021 06:09:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 1625/3125\t\tLoss: 4.593486309051514\n",
      "06/13/2021 06:09:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 1630/3125\t\tLoss: 4.334413528442383\n",
      "06/13/2021 06:09:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 1635/3125\t\tLoss: 4.679746627807617\n",
      "06/13/2021 06:09:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 1640/3125\t\tLoss: 4.552081108093262\n",
      "06/13/2021 06:09:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 1645/3125\t\tLoss: 4.535797119140625\n",
      "06/13/2021 06:10:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 1650/3125\t\tLoss: 4.972107410430908\n",
      "06/13/2021 06:10:10 AM - INFO: Training:: Epoch: 1/16\tBatch: 1655/3125\t\tLoss: 4.567220687866211\n",
      "06/13/2021 06:10:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 1660/3125\t\tLoss: 4.459920883178711\n",
      "06/13/2021 06:10:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 1665/3125\t\tLoss: 4.77187442779541\n",
      "06/13/2021 06:10:42 AM - INFO: Training:: Epoch: 1/16\tBatch: 1670/3125\t\tLoss: 4.638786792755127\n",
      "06/13/2021 06:10:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 1675/3125\t\tLoss: 4.5548553466796875\n",
      "06/13/2021 06:11:03 AM - INFO: Training:: Epoch: 1/16\tBatch: 1680/3125\t\tLoss: 4.4326372146606445\n",
      "06/13/2021 06:11:14 AM - INFO: Training:: Epoch: 1/16\tBatch: 1685/3125\t\tLoss: 4.578585147857666\n",
      "06/13/2021 06:11:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 1690/3125\t\tLoss: 4.335705757141113\n",
      "06/13/2021 06:11:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 1695/3125\t\tLoss: 4.848333835601807\n",
      "06/13/2021 06:11:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 1700/3125\t\tLoss: 4.83113956451416\n",
      "06/13/2021 06:11:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 1705/3125\t\tLoss: 4.850974082946777\n",
      "06/13/2021 06:12:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 1710/3125\t\tLoss: 4.192824363708496\n",
      "06/13/2021 06:12:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 1715/3125\t\tLoss: 4.826535224914551\n",
      "06/13/2021 06:12:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 1720/3125\t\tLoss: 4.480196475982666\n",
      "06/13/2021 06:12:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 1725/3125\t\tLoss: 4.408110618591309\n",
      "06/13/2021 06:12:50 AM - INFO: Training:: Epoch: 1/16\tBatch: 1730/3125\t\tLoss: 4.700215816497803\n",
      "06/13/2021 06:13:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 1735/3125\t\tLoss: 4.938363075256348\n",
      "06/13/2021 06:13:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 1740/3125\t\tLoss: 4.5393476486206055\n",
      "06/13/2021 06:13:24 AM - INFO: Training:: Epoch: 1/16\tBatch: 1745/3125\t\tLoss: 4.602397441864014\n",
      "06/13/2021 06:13:35 AM - INFO: Training:: Epoch: 1/16\tBatch: 1750/3125\t\tLoss: 4.7013044357299805\n",
      "06/13/2021 06:13:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 1755/3125\t\tLoss: 4.899197101593018\n",
      "06/13/2021 06:13:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 1760/3125\t\tLoss: 4.238638877868652\n",
      "06/13/2021 06:14:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 1765/3125\t\tLoss: 4.68032169342041\n",
      "06/13/2021 06:14:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 1770/3125\t\tLoss: 4.437410831451416\n",
      "06/13/2021 06:14:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 1775/3125\t\tLoss: 4.701710224151611\n",
      "06/13/2021 06:14:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 1780/3125\t\tLoss: 4.3871636390686035\n",
      "06/13/2021 06:14:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 1785/3125\t\tLoss: 4.219793796539307\n",
      "06/13/2021 06:15:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 1790/3125\t\tLoss: 4.295670986175537\n",
      "06/13/2021 06:15:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 1795/3125\t\tLoss: 4.586136817932129\n",
      "06/13/2021 06:15:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 1800/3125\t\tLoss: 4.80015230178833\n",
      "06/13/2021 06:15:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 1805/3125\t\tLoss: 4.569159984588623\n",
      "06/13/2021 06:15:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 1810/3125\t\tLoss: 4.961032867431641\n",
      "06/13/2021 06:15:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 1815/3125\t\tLoss: 4.627379894256592\n",
      "06/13/2021 06:16:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 1820/3125\t\tLoss: 4.556659698486328\n",
      "06/13/2021 06:16:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 1825/3125\t\tLoss: 4.336155414581299\n",
      "06/13/2021 06:16:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 1830/3125\t\tLoss: 4.712177276611328\n",
      "06/13/2021 06:16:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 1835/3125\t\tLoss: 4.8597636222839355\n",
      "06/13/2021 06:16:50 AM - INFO: Training:: Epoch: 1/16\tBatch: 1840/3125\t\tLoss: 4.911651134490967\n",
      "06/13/2021 06:17:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 1845/3125\t\tLoss: 4.542051792144775\n",
      "06/13/2021 06:17:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 1850/3125\t\tLoss: 4.71748685836792\n",
      "06/13/2021 06:17:24 AM - INFO: Training:: Epoch: 1/16\tBatch: 1855/3125\t\tLoss: 4.483284950256348\n",
      "06/13/2021 06:17:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 1860/3125\t\tLoss: 4.350804805755615\n",
      "06/13/2021 06:17:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 1865/3125\t\tLoss: 4.353833198547363\n",
      "06/13/2021 06:18:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 1870/3125\t\tLoss: 4.683028697967529\n",
      "06/13/2021 06:18:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 1875/3125\t\tLoss: 4.468023300170898\n",
      "06/13/2021 06:18:24 AM - INFO: Training:: Epoch: 1/16\tBatch: 1880/3125\t\tLoss: 4.483115196228027\n",
      "06/13/2021 06:18:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 1885/3125\t\tLoss: 4.339014053344727\n",
      "06/13/2021 06:18:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 1890/3125\t\tLoss: 4.561357021331787\n",
      "06/13/2021 06:19:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 1895/3125\t\tLoss: 4.44038200378418\n",
      "06/13/2021 06:19:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 1900/3125\t\tLoss: 4.41934871673584\n",
      "06/13/2021 06:19:22 AM - INFO: Training:: Epoch: 1/16\tBatch: 1905/3125\t\tLoss: 4.364429950714111\n",
      "06/13/2021 06:19:34 AM - INFO: Training:: Epoch: 1/16\tBatch: 1910/3125\t\tLoss: 4.576116561889648\n",
      "06/13/2021 06:19:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 1915/3125\t\tLoss: 4.6110734939575195\n",
      "06/13/2021 06:19:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 1920/3125\t\tLoss: 4.616688251495361\n",
      "06/13/2021 06:20:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 1925/3125\t\tLoss: 4.693017482757568\n",
      "06/13/2021 06:20:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 1930/3125\t\tLoss: 4.352181434631348\n",
      "06/13/2021 06:20:32 AM - INFO: Training:: Epoch: 1/16\tBatch: 1935/3125\t\tLoss: 4.676726818084717\n",
      "06/13/2021 06:20:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 1940/3125\t\tLoss: 4.039764881134033\n",
      "06/13/2021 06:20:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 1945/3125\t\tLoss: 4.244453430175781\n",
      "06/13/2021 06:21:04 AM - INFO: Training:: Epoch: 1/16\tBatch: 1950/3125\t\tLoss: 4.2050347328186035\n",
      "06/13/2021 06:21:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 1955/3125\t\tLoss: 4.816535949707031\n",
      "06/13/2021 06:21:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 1960/3125\t\tLoss: 4.501545429229736\n",
      "06/13/2021 06:21:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 1965/3125\t\tLoss: 4.4384765625\n",
      "06/13/2021 06:21:47 AM - INFO: Training:: Epoch: 1/16\tBatch: 1970/3125\t\tLoss: 4.624390602111816\n",
      "06/13/2021 06:21:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 1975/3125\t\tLoss: 4.590044975280762\n",
      "06/13/2021 06:22:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 1980/3125\t\tLoss: 4.305652141571045\n",
      "06/13/2021 06:22:20 AM - INFO: Training:: Epoch: 1/16\tBatch: 1985/3125\t\tLoss: 4.234764099121094\n",
      "06/13/2021 06:22:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 1990/3125\t\tLoss: 4.708571434020996\n",
      "06/13/2021 06:22:42 AM - INFO: Training:: Epoch: 1/16\tBatch: 1995/3125\t\tLoss: 4.628609657287598\n",
      "06/13/2021 06:22:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 2000/3125\t\tLoss: 4.274040222167969\n",
      "06/13/2021 06:23:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 2005/3125\t\tLoss: 4.343760013580322\n",
      "06/13/2021 06:23:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 2010/3125\t\tLoss: 4.193328857421875\n",
      "06/13/2021 06:23:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 2015/3125\t\tLoss: 4.650781154632568\n",
      "06/13/2021 06:23:34 AM - INFO: Training:: Epoch: 1/16\tBatch: 2020/3125\t\tLoss: 4.6157145500183105\n",
      "06/13/2021 06:23:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 2025/3125\t\tLoss: 4.386612892150879\n",
      "06/13/2021 06:23:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 2030/3125\t\tLoss: 4.507434844970703\n",
      "06/13/2021 06:24:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 2035/3125\t\tLoss: 4.539809226989746\n",
      "06/13/2021 06:24:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 2040/3125\t\tLoss: 4.642147064208984\n",
      "06/13/2021 06:24:30 AM - INFO: Training:: Epoch: 1/16\tBatch: 2045/3125\t\tLoss: 4.765836238861084\n",
      "06/13/2021 06:24:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 2050/3125\t\tLoss: 4.586609363555908\n",
      "06/13/2021 06:24:50 AM - INFO: Training:: Epoch: 1/16\tBatch: 2055/3125\t\tLoss: 4.440159797668457\n",
      "06/13/2021 06:25:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 2060/3125\t\tLoss: 4.508904457092285\n",
      "06/13/2021 06:25:10 AM - INFO: Training:: Epoch: 1/16\tBatch: 2065/3125\t\tLoss: 4.72803258895874\n",
      "06/13/2021 06:25:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 2070/3125\t\tLoss: 4.499244689941406\n",
      "06/13/2021 06:25:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 2075/3125\t\tLoss: 4.674252986907959\n",
      "06/13/2021 06:25:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 2080/3125\t\tLoss: 4.6659064292907715\n",
      "06/13/2021 06:25:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 2085/3125\t\tLoss: 4.631814002990723\n",
      "06/13/2021 06:26:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 2090/3125\t\tLoss: 4.618196964263916\n",
      "06/13/2021 06:26:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 2095/3125\t\tLoss: 4.461814880371094\n",
      "06/13/2021 06:26:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 2100/3125\t\tLoss: 4.486363410949707\n",
      "06/13/2021 06:26:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 2105/3125\t\tLoss: 4.704503536224365\n",
      "06/13/2021 06:26:44 AM - INFO: Training:: Epoch: 1/16\tBatch: 2110/3125\t\tLoss: 4.425481796264648\n",
      "06/13/2021 06:26:54 AM - INFO: Training:: Epoch: 1/16\tBatch: 2115/3125\t\tLoss: 4.173678398132324\n",
      "06/13/2021 06:27:05 AM - INFO: Training:: Epoch: 1/16\tBatch: 2120/3125\t\tLoss: 4.271867752075195\n",
      "06/13/2021 06:27:15 AM - INFO: Training:: Epoch: 1/16\tBatch: 2125/3125\t\tLoss: 4.3531365394592285\n",
      "06/13/2021 06:27:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 2130/3125\t\tLoss: 4.309785842895508\n",
      "06/13/2021 06:27:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 2135/3125\t\tLoss: 4.495381832122803\n",
      "06/13/2021 06:27:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 2140/3125\t\tLoss: 4.377377033233643\n",
      "06/13/2021 06:27:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 2145/3125\t\tLoss: 4.750864028930664\n",
      "06/13/2021 06:28:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 2150/3125\t\tLoss: 4.049551010131836\n",
      "06/13/2021 06:28:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 2155/3125\t\tLoss: 4.311139106750488\n",
      "06/13/2021 06:28:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 2160/3125\t\tLoss: 4.563071250915527\n",
      "06/13/2021 06:28:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 2165/3125\t\tLoss: 3.918361186981201\n",
      "06/13/2021 06:28:47 AM - INFO: Training:: Epoch: 1/16\tBatch: 2170/3125\t\tLoss: 4.40283727645874\n",
      "06/13/2021 06:28:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 2175/3125\t\tLoss: 4.8595099449157715\n",
      "06/13/2021 06:29:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 2180/3125\t\tLoss: 4.2514753341674805\n",
      "06/13/2021 06:29:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 2185/3125\t\tLoss: 4.484297275543213\n",
      "06/13/2021 06:29:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 2190/3125\t\tLoss: 4.281286239624023\n",
      "06/13/2021 06:29:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 2195/3125\t\tLoss: 4.626681327819824\n",
      "06/13/2021 06:29:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 2200/3125\t\tLoss: 4.393697738647461\n",
      "06/13/2021 06:29:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 2205/3125\t\tLoss: 4.787714958190918\n",
      "06/13/2021 06:30:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 2210/3125\t\tLoss: 4.687244892120361\n",
      "06/13/2021 06:30:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 2215/3125\t\tLoss: 4.569399833679199\n",
      "06/13/2021 06:30:30 AM - INFO: Training:: Epoch: 1/16\tBatch: 2220/3125\t\tLoss: 4.886491775512695\n",
      "06/13/2021 06:30:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 2225/3125\t\tLoss: 4.498539924621582\n",
      "06/13/2021 06:30:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 2230/3125\t\tLoss: 4.647289752960205\n",
      "06/13/2021 06:31:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 2235/3125\t\tLoss: 4.392714500427246\n",
      "06/13/2021 06:31:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 2240/3125\t\tLoss: 4.277963161468506\n",
      "06/13/2021 06:31:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 2245/3125\t\tLoss: 3.9480273723602295\n",
      "06/13/2021 06:31:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 2250/3125\t\tLoss: 4.300522327423096\n",
      "06/13/2021 06:31:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 2255/3125\t\tLoss: 4.480395793914795\n",
      "06/13/2021 06:31:54 AM - INFO: Training:: Epoch: 1/16\tBatch: 2260/3125\t\tLoss: 4.351264953613281\n",
      "06/13/2021 06:32:04 AM - INFO: Training:: Epoch: 1/16\tBatch: 2265/3125\t\tLoss: 4.247406005859375\n",
      "06/13/2021 06:32:15 AM - INFO: Training:: Epoch: 1/16\tBatch: 2270/3125\t\tLoss: 4.505387783050537\n",
      "06/13/2021 06:32:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 2275/3125\t\tLoss: 4.2183122634887695\n",
      "06/13/2021 06:32:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 2280/3125\t\tLoss: 4.507463455200195\n",
      "06/13/2021 06:32:48 AM - INFO: Training:: Epoch: 1/16\tBatch: 2285/3125\t\tLoss: 4.879620552062988\n",
      "06/13/2021 06:32:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 2290/3125\t\tLoss: 4.397315502166748\n",
      "06/13/2021 06:33:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 2295/3125\t\tLoss: 4.53741455078125\n",
      "06/13/2021 06:33:22 AM - INFO: Training:: Epoch: 1/16\tBatch: 2300/3125\t\tLoss: 4.763574600219727\n",
      "06/13/2021 06:33:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 2305/3125\t\tLoss: 4.342705726623535\n",
      "06/13/2021 06:33:44 AM - INFO: Training:: Epoch: 1/16\tBatch: 2310/3125\t\tLoss: 4.411796569824219\n",
      "06/13/2021 06:33:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 2315/3125\t\tLoss: 4.350768566131592\n",
      "06/13/2021 06:34:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 2320/3125\t\tLoss: 4.568336009979248\n",
      "06/13/2021 06:34:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 2325/3125\t\tLoss: 4.245397567749023\n",
      "06/13/2021 06:34:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 2330/3125\t\tLoss: 4.403669357299805\n",
      "06/13/2021 06:34:42 AM - INFO: Training:: Epoch: 1/16\tBatch: 2335/3125\t\tLoss: 4.594058513641357\n",
      "06/13/2021 06:34:54 AM - INFO: Training:: Epoch: 1/16\tBatch: 2340/3125\t\tLoss: 4.609285354614258\n",
      "06/13/2021 06:35:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 2345/3125\t\tLoss: 4.406635284423828\n",
      "06/13/2021 06:35:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 2350/3125\t\tLoss: 4.2502665519714355\n",
      "06/13/2021 06:35:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 2355/3125\t\tLoss: 4.488157749176025\n",
      "06/13/2021 06:35:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 2360/3125\t\tLoss: 4.172989845275879\n",
      "06/13/2021 06:35:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 2365/3125\t\tLoss: 4.28334903717041\n",
      "06/13/2021 06:36:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 2370/3125\t\tLoss: 4.095839023590088\n",
      "06/13/2021 06:36:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 2375/3125\t\tLoss: 4.249391078948975\n",
      "06/13/2021 06:36:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 2380/3125\t\tLoss: 4.507991790771484\n",
      "06/13/2021 06:36:32 AM - INFO: Training:: Epoch: 1/16\tBatch: 2385/3125\t\tLoss: 4.219716548919678\n",
      "06/13/2021 06:36:42 AM - INFO: Training:: Epoch: 1/16\tBatch: 2390/3125\t\tLoss: 4.373553276062012\n",
      "06/13/2021 06:36:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 2395/3125\t\tLoss: 3.9264628887176514\n",
      "06/13/2021 06:37:03 AM - INFO: Training:: Epoch: 1/16\tBatch: 2400/3125\t\tLoss: 4.393284797668457\n",
      "06/13/2021 06:37:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 2405/3125\t\tLoss: 4.477973937988281\n",
      "06/13/2021 06:37:22 AM - INFO: Training:: Epoch: 1/16\tBatch: 2410/3125\t\tLoss: 4.446192264556885\n",
      "06/13/2021 06:37:32 AM - INFO: Training:: Epoch: 1/16\tBatch: 2415/3125\t\tLoss: 4.10646915435791\n",
      "06/13/2021 06:37:42 AM - INFO: Training:: Epoch: 1/16\tBatch: 2420/3125\t\tLoss: 4.371520042419434\n",
      "06/13/2021 06:37:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 2425/3125\t\tLoss: 4.14242696762085\n",
      "06/13/2021 06:38:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 2430/3125\t\tLoss: 4.391068458557129\n",
      "06/13/2021 06:38:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 2435/3125\t\tLoss: 4.5537919998168945\n",
      "06/13/2021 06:38:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 2440/3125\t\tLoss: 4.501077175140381\n",
      "06/13/2021 06:38:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 2445/3125\t\tLoss: 4.241224765777588\n",
      "06/13/2021 06:38:44 AM - INFO: Training:: Epoch: 1/16\tBatch: 2450/3125\t\tLoss: 4.334017753601074\n",
      "06/13/2021 06:38:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 2455/3125\t\tLoss: 4.581919193267822\n",
      "06/13/2021 06:39:05 AM - INFO: Training:: Epoch: 1/16\tBatch: 2460/3125\t\tLoss: 4.266266345977783\n",
      "06/13/2021 06:39:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 2465/3125\t\tLoss: 4.189693927764893\n",
      "06/13/2021 06:39:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 2470/3125\t\tLoss: 3.7461462020874023\n",
      "06/13/2021 06:39:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 2475/3125\t\tLoss: 4.484512805938721\n",
      "06/13/2021 06:39:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 2480/3125\t\tLoss: 4.1789021492004395\n",
      "06/13/2021 06:39:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 2485/3125\t\tLoss: 4.675782203674316\n",
      "06/13/2021 06:40:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 2490/3125\t\tLoss: 4.29623556137085\n",
      "06/13/2021 06:40:15 AM - INFO: Training:: Epoch: 1/16\tBatch: 2495/3125\t\tLoss: 4.405966758728027\n",
      "06/13/2021 06:40:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 2500/3125\t\tLoss: 4.0806779861450195\n",
      "06/13/2021 06:40:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 2505/3125\t\tLoss: 4.540567874908447\n",
      "06/13/2021 06:40:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 2510/3125\t\tLoss: 4.28226375579834\n",
      "06/13/2021 06:40:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 2515/3125\t\tLoss: 4.347755432128906\n",
      "06/13/2021 06:41:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 2520/3125\t\tLoss: 4.295859336853027\n",
      "06/13/2021 06:41:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 2525/3125\t\tLoss: 4.694357395172119\n",
      "06/13/2021 06:41:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 2530/3125\t\tLoss: 4.226879596710205\n",
      "06/13/2021 06:41:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 2535/3125\t\tLoss: 4.408577919006348\n",
      "06/13/2021 06:41:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 2540/3125\t\tLoss: 4.256575584411621\n",
      "06/13/2021 06:41:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 2545/3125\t\tLoss: 4.724987506866455\n",
      "06/13/2021 06:42:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 2550/3125\t\tLoss: 4.4195685386657715\n",
      "06/13/2021 06:42:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 2555/3125\t\tLoss: 4.412078380584717\n",
      "06/13/2021 06:42:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 2560/3125\t\tLoss: 4.270256996154785\n",
      "06/13/2021 06:42:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 2565/3125\t\tLoss: 4.279422760009766\n",
      "06/13/2021 06:42:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 2570/3125\t\tLoss: 4.23996639251709\n",
      "06/13/2021 06:43:04 AM - INFO: Training:: Epoch: 1/16\tBatch: 2575/3125\t\tLoss: 4.322912216186523\n",
      "06/13/2021 06:43:14 AM - INFO: Training:: Epoch: 1/16\tBatch: 2580/3125\t\tLoss: 4.2298078536987305\n",
      "06/13/2021 06:43:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 2585/3125\t\tLoss: 4.332525730133057\n",
      "06/13/2021 06:43:35 AM - INFO: Training:: Epoch: 1/16\tBatch: 2590/3125\t\tLoss: 4.186286926269531\n",
      "06/13/2021 06:43:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 2595/3125\t\tLoss: 4.504557132720947\n",
      "06/13/2021 06:43:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 2600/3125\t\tLoss: 4.343623638153076\n",
      "06/13/2021 06:44:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 2605/3125\t\tLoss: 4.198487758636475\n",
      "06/13/2021 06:44:19 AM - INFO: Training:: Epoch: 1/16\tBatch: 2610/3125\t\tLoss: 4.300500392913818\n",
      "06/13/2021 06:44:29 AM - INFO: Training:: Epoch: 1/16\tBatch: 2615/3125\t\tLoss: 4.450001239776611\n",
      "06/13/2021 06:44:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 2620/3125\t\tLoss: 4.23777437210083\n",
      "06/13/2021 06:44:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 2625/3125\t\tLoss: 4.216428279876709\n",
      "06/13/2021 06:44:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 2630/3125\t\tLoss: 4.163501262664795\n",
      "06/13/2021 06:45:10 AM - INFO: Training:: Epoch: 1/16\tBatch: 2635/3125\t\tLoss: 4.206014633178711\n",
      "06/13/2021 06:45:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 2640/3125\t\tLoss: 4.60457181930542\n",
      "06/13/2021 06:45:33 AM - INFO: Training:: Epoch: 1/16\tBatch: 2645/3125\t\tLoss: 4.136714935302734\n",
      "06/13/2021 06:45:44 AM - INFO: Training:: Epoch: 1/16\tBatch: 2650/3125\t\tLoss: 4.429880619049072\n",
      "06/13/2021 06:45:54 AM - INFO: Training:: Epoch: 1/16\tBatch: 2655/3125\t\tLoss: 4.380424976348877\n",
      "06/13/2021 06:46:05 AM - INFO: Training:: Epoch: 1/16\tBatch: 2660/3125\t\tLoss: 4.3468828201293945\n",
      "06/13/2021 06:46:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 2665/3125\t\tLoss: 4.293425559997559\n",
      "06/13/2021 06:46:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 2670/3125\t\tLoss: 4.530965328216553\n",
      "06/13/2021 06:46:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 2675/3125\t\tLoss: 4.0706892013549805\n",
      "06/13/2021 06:46:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 2680/3125\t\tLoss: 3.935025215148926\n",
      "06/13/2021 06:47:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 2685/3125\t\tLoss: 4.164800643920898\n",
      "06/13/2021 06:47:13 AM - INFO: Training:: Epoch: 1/16\tBatch: 2690/3125\t\tLoss: 4.5863471031188965\n",
      "06/13/2021 06:47:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 2695/3125\t\tLoss: 4.373171329498291\n",
      "06/13/2021 06:47:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 2700/3125\t\tLoss: 4.333922863006592\n",
      "06/13/2021 06:47:47 AM - INFO: Training:: Epoch: 1/16\tBatch: 2705/3125\t\tLoss: 4.70599365234375\n",
      "06/13/2021 06:47:58 AM - INFO: Training:: Epoch: 1/16\tBatch: 2710/3125\t\tLoss: 4.0391998291015625\n",
      "06/13/2021 06:48:09 AM - INFO: Training:: Epoch: 1/16\tBatch: 2715/3125\t\tLoss: 4.505901336669922\n",
      "06/13/2021 06:48:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 2720/3125\t\tLoss: 3.7513060569763184\n",
      "06/13/2021 06:48:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 2725/3125\t\tLoss: 4.443701267242432\n",
      "06/13/2021 06:48:42 AM - INFO: Training:: Epoch: 1/16\tBatch: 2730/3125\t\tLoss: 3.8703129291534424\n",
      "06/13/2021 06:48:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 2735/3125\t\tLoss: 4.203221321105957\n",
      "06/13/2021 06:49:02 AM - INFO: Training:: Epoch: 1/16\tBatch: 2740/3125\t\tLoss: 4.348287105560303\n",
      "06/13/2021 06:49:12 AM - INFO: Training:: Epoch: 1/16\tBatch: 2745/3125\t\tLoss: 4.193733215332031\n",
      "06/13/2021 06:49:23 AM - INFO: Training:: Epoch: 1/16\tBatch: 2750/3125\t\tLoss: 4.172991752624512\n",
      "06/13/2021 06:49:32 AM - INFO: Training:: Epoch: 1/16\tBatch: 2755/3125\t\tLoss: 4.172626495361328\n",
      "06/13/2021 06:49:43 AM - INFO: Training:: Epoch: 1/16\tBatch: 2760/3125\t\tLoss: 4.734823226928711\n",
      "06/13/2021 06:49:53 AM - INFO: Training:: Epoch: 1/16\tBatch: 2765/3125\t\tLoss: 4.142159938812256\n",
      "06/13/2021 06:50:03 AM - INFO: Training:: Epoch: 1/16\tBatch: 2770/3125\t\tLoss: 4.244533538818359\n",
      "06/13/2021 06:50:14 AM - INFO: Training:: Epoch: 1/16\tBatch: 2775/3125\t\tLoss: 4.138433456420898\n",
      "06/13/2021 06:50:24 AM - INFO: Training:: Epoch: 1/16\tBatch: 2780/3125\t\tLoss: 4.3578410148620605\n",
      "06/13/2021 06:50:34 AM - INFO: Training:: Epoch: 1/16\tBatch: 2785/3125\t\tLoss: 4.466728687286377\n",
      "06/13/2021 06:50:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 2790/3125\t\tLoss: 4.392238616943359\n",
      "06/13/2021 06:50:55 AM - INFO: Training:: Epoch: 1/16\tBatch: 2795/3125\t\tLoss: 4.110965251922607\n",
      "06/13/2021 06:51:04 AM - INFO: Training:: Epoch: 1/16\tBatch: 2800/3125\t\tLoss: 3.908529281616211\n",
      "06/13/2021 06:51:15 AM - INFO: Training:: Epoch: 1/16\tBatch: 2805/3125\t\tLoss: 4.114757061004639\n",
      "06/13/2021 06:51:25 AM - INFO: Training:: Epoch: 1/16\tBatch: 2810/3125\t\tLoss: 4.325766563415527\n",
      "06/13/2021 06:51:35 AM - INFO: Training:: Epoch: 1/16\tBatch: 2815/3125\t\tLoss: 4.205770492553711\n",
      "06/13/2021 06:51:45 AM - INFO: Training:: Epoch: 1/16\tBatch: 2820/3125\t\tLoss: 4.684210300445557\n",
      "06/13/2021 06:51:54 AM - INFO: Training:: Epoch: 1/16\tBatch: 2825/3125\t\tLoss: 4.198532581329346\n",
      "06/13/2021 06:52:04 AM - INFO: Training:: Epoch: 1/16\tBatch: 2830/3125\t\tLoss: 3.9350521564483643\n",
      "06/13/2021 06:52:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 2835/3125\t\tLoss: 4.674591064453125\n",
      "06/13/2021 06:52:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 2840/3125\t\tLoss: 3.9140090942382812\n",
      "06/13/2021 06:52:39 AM - INFO: Training:: Epoch: 1/16\tBatch: 2845/3125\t\tLoss: 4.249795913696289\n",
      "06/13/2021 06:52:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 2850/3125\t\tLoss: 4.222340106964111\n",
      "06/13/2021 06:52:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 2855/3125\t\tLoss: 4.291759014129639\n",
      "06/13/2021 06:53:10 AM - INFO: Training:: Epoch: 1/16\tBatch: 2860/3125\t\tLoss: 4.274044513702393\n",
      "06/13/2021 06:53:20 AM - INFO: Training:: Epoch: 1/16\tBatch: 2865/3125\t\tLoss: 4.731888771057129\n",
      "06/13/2021 06:53:30 AM - INFO: Training:: Epoch: 1/16\tBatch: 2870/3125\t\tLoss: 4.499479293823242\n",
      "06/13/2021 06:53:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 2875/3125\t\tLoss: 4.464846611022949\n",
      "06/13/2021 06:53:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 2880/3125\t\tLoss: 4.263393402099609\n",
      "06/13/2021 06:54:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 2885/3125\t\tLoss: 4.235832691192627\n",
      "06/13/2021 06:54:10 AM - INFO: Training:: Epoch: 1/16\tBatch: 2890/3125\t\tLoss: 4.441877365112305\n",
      "06/13/2021 06:54:20 AM - INFO: Training:: Epoch: 1/16\tBatch: 2895/3125\t\tLoss: 4.020835876464844\n",
      "06/13/2021 06:54:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 2900/3125\t\tLoss: 4.101452350616455\n",
      "06/13/2021 06:54:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 2905/3125\t\tLoss: 4.3760881423950195\n",
      "06/13/2021 06:54:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 2910/3125\t\tLoss: 4.17708683013916\n",
      "06/13/2021 06:55:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 2915/3125\t\tLoss: 4.4292120933532715\n",
      "06/13/2021 06:55:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 2920/3125\t\tLoss: 4.192607879638672\n",
      "06/13/2021 06:55:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 2925/3125\t\tLoss: 4.444584846496582\n",
      "06/13/2021 06:55:32 AM - INFO: Training:: Epoch: 1/16\tBatch: 2930/3125\t\tLoss: 3.969310760498047\n",
      "06/13/2021 06:55:42 AM - INFO: Training:: Epoch: 1/16\tBatch: 2935/3125\t\tLoss: 4.024892807006836\n",
      "06/13/2021 06:55:52 AM - INFO: Training:: Epoch: 1/16\tBatch: 2940/3125\t\tLoss: 4.156849384307861\n",
      "06/13/2021 06:56:01 AM - INFO: Training:: Epoch: 1/16\tBatch: 2945/3125\t\tLoss: 4.115372180938721\n",
      "06/13/2021 06:56:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 2950/3125\t\tLoss: 4.405419826507568\n",
      "06/13/2021 06:56:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 2955/3125\t\tLoss: 4.077094078063965\n",
      "06/13/2021 06:56:31 AM - INFO: Training:: Epoch: 1/16\tBatch: 2960/3125\t\tLoss: 4.287984371185303\n",
      "06/13/2021 06:56:41 AM - INFO: Training:: Epoch: 1/16\tBatch: 2965/3125\t\tLoss: 4.45442533493042\n",
      "06/13/2021 06:56:51 AM - INFO: Training:: Epoch: 1/16\tBatch: 2970/3125\t\tLoss: 3.897796392440796\n",
      "06/13/2021 06:57:00 AM - INFO: Training:: Epoch: 1/16\tBatch: 2975/3125\t\tLoss: 4.320029258728027\n",
      "06/13/2021 06:57:11 AM - INFO: Training:: Epoch: 1/16\tBatch: 2980/3125\t\tLoss: 4.408938407897949\n",
      "06/13/2021 06:57:21 AM - INFO: Training:: Epoch: 1/16\tBatch: 2985/3125\t\tLoss: 3.984697103500366\n",
      "06/13/2021 06:57:30 AM - INFO: Training:: Epoch: 1/16\tBatch: 2990/3125\t\tLoss: 4.315948009490967\n",
      "06/13/2021 06:57:40 AM - INFO: Training:: Epoch: 1/16\tBatch: 2995/3125\t\tLoss: 4.239049911499023\n",
      "06/13/2021 06:57:49 AM - INFO: Training:: Epoch: 1/16\tBatch: 3000/3125\t\tLoss: 4.244894504547119\n",
      "06/13/2021 06:57:59 AM - INFO: Training:: Epoch: 1/16\tBatch: 3005/3125\t\tLoss: 4.416483402252197\n",
      "06/13/2021 06:58:08 AM - INFO: Training:: Epoch: 1/16\tBatch: 3010/3125\t\tLoss: 4.355401039123535\n",
      "06/13/2021 06:58:18 AM - INFO: Training:: Epoch: 1/16\tBatch: 3015/3125\t\tLoss: 4.326260089874268\n",
      "06/13/2021 06:58:28 AM - INFO: Training:: Epoch: 1/16\tBatch: 3020/3125\t\tLoss: 4.672053813934326\n",
      "06/13/2021 06:58:38 AM - INFO: Training:: Epoch: 1/16\tBatch: 3025/3125\t\tLoss: 4.309110641479492\n",
      "06/13/2021 06:58:47 AM - INFO: Training:: Epoch: 1/16\tBatch: 3030/3125\t\tLoss: 4.5080413818359375\n",
      "06/13/2021 06:58:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 3035/3125\t\tLoss: 4.212854862213135\n",
      "06/13/2021 06:59:07 AM - INFO: Training:: Epoch: 1/16\tBatch: 3040/3125\t\tLoss: 4.642853260040283\n",
      "06/13/2021 06:59:17 AM - INFO: Training:: Epoch: 1/16\tBatch: 3045/3125\t\tLoss: 4.4419636726379395\n",
      "06/13/2021 06:59:27 AM - INFO: Training:: Epoch: 1/16\tBatch: 3050/3125\t\tLoss: 4.260224342346191\n",
      "06/13/2021 06:59:37 AM - INFO: Training:: Epoch: 1/16\tBatch: 3055/3125\t\tLoss: 4.1156697273254395\n",
      "06/13/2021 06:59:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 3060/3125\t\tLoss: 3.7906334400177\n",
      "06/13/2021 06:59:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 3065/3125\t\tLoss: 4.570542335510254\n",
      "06/13/2021 07:00:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 3070/3125\t\tLoss: 4.003655910491943\n",
      "06/13/2021 07:00:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 3075/3125\t\tLoss: 3.806718111038208\n",
      "06/13/2021 07:00:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 3080/3125\t\tLoss: 4.506731986999512\n",
      "06/13/2021 07:00:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 3085/3125\t\tLoss: 4.4491190910339355\n",
      "06/13/2021 07:00:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 3090/3125\t\tLoss: 4.193788051605225\n",
      "06/13/2021 07:00:57 AM - INFO: Training:: Epoch: 1/16\tBatch: 3095/3125\t\tLoss: 4.189742565155029\n",
      "06/13/2021 07:01:06 AM - INFO: Training:: Epoch: 1/16\tBatch: 3100/3125\t\tLoss: 4.254926681518555\n",
      "06/13/2021 07:01:16 AM - INFO: Training:: Epoch: 1/16\tBatch: 3105/3125\t\tLoss: 4.607268333435059\n",
      "06/13/2021 07:01:26 AM - INFO: Training:: Epoch: 1/16\tBatch: 3110/3125\t\tLoss: 4.233817100524902\n",
      "06/13/2021 07:01:36 AM - INFO: Training:: Epoch: 1/16\tBatch: 3115/3125\t\tLoss: 4.427982807159424\n",
      "06/13/2021 07:01:46 AM - INFO: Training:: Epoch: 1/16\tBatch: 3120/3125\t\tLoss: 4.25171422958374\n",
      "06/13/2021 07:01:56 AM - INFO: Training:: Epoch: 1/16\tBatch: 3125/3125\t\tLoss: 4.160649299621582\n",
      "06/13/2021 07:02:00 AM - INFO: Validation:: Epoch: 1/16\tBatch: 5/3125\t\tLoss: 6.866816997528076\n",
      "06/13/2021 07:02:04 AM - INFO: Validation:: Epoch: 1/16\tBatch: 10/3125\t\tLoss: 6.968990325927734\n",
      "06/13/2021 07:02:07 AM - INFO: Validation:: Epoch: 1/16\tBatch: 15/3125\t\tLoss: 7.0203166007995605\n",
      "06/13/2021 07:02:10 AM - INFO: Validation:: Epoch: 1/16\tBatch: 20/3125\t\tLoss: 7.280390739440918\n",
      "06/13/2021 07:02:14 AM - INFO: Validation:: Epoch: 1/16\tBatch: 25/3125\t\tLoss: 6.950974941253662\n",
      "06/13/2021 07:02:17 AM - INFO: Validation:: Epoch: 1/16\tBatch: 30/3125\t\tLoss: 7.174036502838135\n",
      "06/13/2021 07:02:20 AM - INFO: Validation:: Epoch: 1/16\tBatch: 35/3125\t\tLoss: 6.856995582580566\n",
      "06/13/2021 07:02:23 AM - INFO: Validation:: Epoch: 1/16\tBatch: 40/3125\t\tLoss: 7.200435638427734\n",
      "06/13/2021 07:02:26 AM - INFO: Validation:: Epoch: 1/16\tBatch: 45/3125\t\tLoss: 6.176520824432373\n",
      "06/13/2021 07:02:29 AM - INFO: Validation:: Epoch: 1/16\tBatch: 50/3125\t\tLoss: 7.023005485534668\n",
      "06/13/2021 07:02:32 AM - INFO: Validation:: Epoch: 1/16\tBatch: 55/3125\t\tLoss: 6.3288350105285645\n",
      "06/13/2021 07:02:35 AM - INFO: Validation:: Epoch: 1/16\tBatch: 60/3125\t\tLoss: 6.972343921661377\n",
      "06/13/2021 07:02:38 AM - INFO: Validation:: Epoch: 1/16\tBatch: 65/3125\t\tLoss: 6.934368133544922\n",
      "06/13/2021 07:02:41 AM - INFO: Validation:: Epoch: 1/16\tBatch: 70/3125\t\tLoss: 6.730668544769287\n",
      "06/13/2021 07:02:44 AM - INFO: Validation:: Epoch: 1/16\tBatch: 75/3125\t\tLoss: 7.126637935638428\n",
      "06/13/2021 07:02:47 AM - INFO: Validation:: Epoch: 1/16\tBatch: 80/3125\t\tLoss: 6.676408767700195\n",
      "06/13/2021 07:02:49 AM - INFO: Validation:: Epoch: 1/16\tBatch: 85/3125\t\tLoss: 7.076215744018555\n",
      "06/13/2021 07:02:52 AM - INFO: Validation:: Epoch: 1/16\tBatch: 90/3125\t\tLoss: 7.644572734832764\n",
      "06/13/2021 07:02:55 AM - INFO: Validation:: Epoch: 1/16\tBatch: 95/3125\t\tLoss: 7.179203987121582\n",
      "06/13/2021 07:02:58 AM - INFO: Validation:: Epoch: 1/16\tBatch: 100/3125\t\tLoss: 6.892449378967285\n",
      "06/13/2021 07:03:01 AM - INFO: Validation:: Epoch: 1/16\tBatch: 105/3125\t\tLoss: 6.674096584320068\n",
      "06/13/2021 07:03:04 AM - INFO: Validation:: Epoch: 1/16\tBatch: 110/3125\t\tLoss: 6.836811065673828\n",
      "06/13/2021 07:03:07 AM - INFO: Validation:: Epoch: 1/16\tBatch: 115/3125\t\tLoss: 6.547107696533203\n",
      "06/13/2021 07:03:10 AM - INFO: Validation:: Epoch: 1/16\tBatch: 120/3125\t\tLoss: 6.454894065856934\n",
      "06/13/2021 07:03:13 AM - INFO: Validation:: Epoch: 1/16\tBatch: 125/3125\t\tLoss: 7.093560218811035\n",
      "06/13/2021 07:03:17 AM - INFO: Validation:: Epoch: 1/16\tBatch: 130/3125\t\tLoss: 6.993256568908691\n",
      "06/13/2021 07:03:20 AM - INFO: Validation:: Epoch: 1/16\tBatch: 135/3125\t\tLoss: 6.826025009155273\n",
      "06/13/2021 07:03:23 AM - INFO: Validation:: Epoch: 1/16\tBatch: 140/3125\t\tLoss: 6.438835620880127\n",
      "06/13/2021 07:03:26 AM - INFO: Validation:: Epoch: 1/16\tBatch: 145/3125\t\tLoss: 6.500112533569336\n",
      "06/13/2021 07:03:29 AM - INFO: Validation:: Epoch: 1/16\tBatch: 150/3125\t\tLoss: 7.299197673797607\n",
      "06/13/2021 07:03:32 AM - INFO: Validation:: Epoch: 1/16\tBatch: 155/3125\t\tLoss: 6.186352729797363\n",
      "06/13/2021 07:03:35 AM - INFO: Validation:: Epoch: 1/16\tBatch: 160/3125\t\tLoss: 6.868594169616699\n",
      "06/13/2021 07:03:38 AM - INFO: Validation:: Epoch: 1/16\tBatch: 165/3125\t\tLoss: 6.3632636070251465\n",
      "06/13/2021 07:03:42 AM - INFO: Validation:: Epoch: 1/16\tBatch: 170/3125\t\tLoss: 7.547375202178955\n",
      "06/13/2021 07:03:45 AM - INFO: Validation:: Epoch: 1/16\tBatch: 175/3125\t\tLoss: 6.622833251953125\n",
      "06/13/2021 07:03:48 AM - INFO: Validation:: Epoch: 1/16\tBatch: 180/3125\t\tLoss: 6.922154426574707\n",
      "06/13/2021 07:03:51 AM - INFO: Validation:: Epoch: 1/16\tBatch: 185/3125\t\tLoss: 6.508260726928711\n",
      "06/13/2021 07:03:54 AM - INFO: Validation:: Epoch: 1/16\tBatch: 190/3125\t\tLoss: 6.552154541015625\n",
      "06/13/2021 07:03:57 AM - INFO: Validation:: Epoch: 1/16\tBatch: 195/3125\t\tLoss: 7.306553363800049\n",
      "06/13/2021 07:04:00 AM - INFO: Validation:: Epoch: 1/16\tBatch: 200/3125\t\tLoss: 6.179617881774902\n",
      "06/13/2021 07:04:03 AM - INFO: Validation:: Epoch: 1/16\tBatch: 205/3125\t\tLoss: 6.406947612762451\n",
      "06/13/2021 07:04:06 AM - INFO: Validation:: Epoch: 1/16\tBatch: 210/3125\t\tLoss: 6.395733833312988\n",
      "06/13/2021 07:04:09 AM - INFO: Validation:: Epoch: 1/16\tBatch: 215/3125\t\tLoss: 7.437180519104004\n",
      "06/13/2021 07:04:12 AM - INFO: Validation:: Epoch: 1/16\tBatch: 220/3125\t\tLoss: 6.5190348625183105\n",
      "06/13/2021 07:04:15 AM - INFO: Validation:: Epoch: 1/16\tBatch: 225/3125\t\tLoss: 6.688106536865234\n",
      "06/13/2021 07:04:18 AM - INFO: Validation:: Epoch: 1/16\tBatch: 230/3125\t\tLoss: 6.862233638763428\n",
      "06/13/2021 07:04:21 AM - INFO: Validation:: Epoch: 1/16\tBatch: 235/3125\t\tLoss: 6.217375755310059\n",
      "06/13/2021 07:04:24 AM - INFO: Validation:: Epoch: 1/16\tBatch: 240/3125\t\tLoss: 6.751697540283203\n",
      "06/13/2021 07:04:27 AM - INFO: Validation:: Epoch: 1/16\tBatch: 245/3125\t\tLoss: 6.34730863571167\n",
      "06/13/2021 07:04:30 AM - INFO: Validation:: Epoch: 1/16\tBatch: 250/3125\t\tLoss: 6.638894557952881\n",
      "06/13/2021 07:04:33 AM - INFO: Validation:: Epoch: 1/16\tBatch: 255/3125\t\tLoss: 6.9704790115356445\n",
      "06/13/2021 07:04:36 AM - INFO: Validation:: Epoch: 1/16\tBatch: 260/3125\t\tLoss: 7.016343593597412\n",
      "06/13/2021 07:04:39 AM - INFO: Validation:: Epoch: 1/16\tBatch: 265/3125\t\tLoss: 7.134070873260498\n",
      "06/13/2021 07:04:42 AM - INFO: Validation:: Epoch: 1/16\tBatch: 270/3125\t\tLoss: 7.026701927185059\n",
      "06/13/2021 07:04:45 AM - INFO: Validation:: Epoch: 1/16\tBatch: 275/3125\t\tLoss: 7.178310394287109\n",
      "06/13/2021 07:04:48 AM - INFO: Validation:: Epoch: 1/16\tBatch: 280/3125\t\tLoss: 6.99653959274292\n",
      "06/13/2021 07:04:51 AM - INFO: Validation:: Epoch: 1/16\tBatch: 285/3125\t\tLoss: 6.784231662750244\n",
      "06/13/2021 07:04:54 AM - INFO: Validation:: Epoch: 1/16\tBatch: 290/3125\t\tLoss: 7.03485107421875\n",
      "06/13/2021 07:04:57 AM - INFO: Validation:: Epoch: 1/16\tBatch: 295/3125\t\tLoss: 6.54530143737793\n",
      "06/13/2021 07:05:00 AM - INFO: Validation:: Epoch: 1/16\tBatch: 300/3125\t\tLoss: 7.126882076263428\n",
      "06/13/2021 07:05:03 AM - INFO: Validation:: Epoch: 1/16\tBatch: 305/3125\t\tLoss: 7.042890548706055\n",
      "06/13/2021 07:05:05 AM - INFO: Validation:: Epoch: 1/16\tBatch: 310/3125\t\tLoss: 6.553907871246338\n",
      "06/13/2021 07:05:07 AM - INFO: Epoch: 2\n",
      "06/13/2021 07:05:14 AM - INFO: Training:: Epoch: 2/16\tBatch: 5/3125\t\tLoss: 4.24345588684082\n",
      "06/13/2021 07:05:21 AM - INFO: Training:: Epoch: 2/16\tBatch: 10/3125\t\tLoss: 4.035475254058838\n",
      "06/13/2021 07:05:28 AM - INFO: Training:: Epoch: 2/16\tBatch: 15/3125\t\tLoss: 4.099975109100342\n",
      "06/13/2021 07:05:35 AM - INFO: Training:: Epoch: 2/16\tBatch: 20/3125\t\tLoss: 3.8276963233947754\n",
      "06/13/2021 07:05:42 AM - INFO: Training:: Epoch: 2/16\tBatch: 25/3125\t\tLoss: 4.247997760772705\n",
      "06/13/2021 07:05:50 AM - INFO: Training:: Epoch: 2/16\tBatch: 30/3125\t\tLoss: 3.6060922145843506\n",
      "06/13/2021 07:05:57 AM - INFO: Training:: Epoch: 2/16\tBatch: 35/3125\t\tLoss: 4.32827091217041\n",
      "06/13/2021 07:06:04 AM - INFO: Training:: Epoch: 2/16\tBatch: 40/3125\t\tLoss: 3.90273118019104\n",
      "06/13/2021 07:06:11 AM - INFO: Training:: Epoch: 2/16\tBatch: 45/3125\t\tLoss: 4.700567245483398\n",
      "06/13/2021 07:06:18 AM - INFO: Training:: Epoch: 2/16\tBatch: 50/3125\t\tLoss: 4.385135173797607\n",
      "06/13/2021 07:06:25 AM - INFO: Training:: Epoch: 2/16\tBatch: 55/3125\t\tLoss: 3.804692268371582\n",
      "06/13/2021 07:06:32 AM - INFO: Training:: Epoch: 2/16\tBatch: 60/3125\t\tLoss: 4.1984968185424805\n",
      "06/13/2021 07:06:39 AM - INFO: Training:: Epoch: 2/16\tBatch: 65/3125\t\tLoss: 4.210567474365234\n",
      "06/13/2021 07:06:47 AM - INFO: Training:: Epoch: 2/16\tBatch: 70/3125\t\tLoss: 4.226682662963867\n",
      "06/13/2021 07:06:54 AM - INFO: Training:: Epoch: 2/16\tBatch: 75/3125\t\tLoss: 4.494676113128662\n",
      "06/13/2021 07:07:01 AM - INFO: Training:: Epoch: 2/16\tBatch: 80/3125\t\tLoss: 3.947047233581543\n",
      "06/13/2021 07:07:08 AM - INFO: Training:: Epoch: 2/16\tBatch: 85/3125\t\tLoss: 4.505622386932373\n",
      "06/13/2021 07:07:15 AM - INFO: Training:: Epoch: 2/16\tBatch: 90/3125\t\tLoss: 4.135011196136475\n",
      "06/13/2021 07:07:22 AM - INFO: Training:: Epoch: 2/16\tBatch: 95/3125\t\tLoss: 4.099136829376221\n",
      "06/13/2021 07:07:30 AM - INFO: Training:: Epoch: 2/16\tBatch: 100/3125\t\tLoss: 3.8575499057769775\n",
      "06/13/2021 07:07:37 AM - INFO: Training:: Epoch: 2/16\tBatch: 105/3125\t\tLoss: 3.8058652877807617\n",
      "06/13/2021 07:07:44 AM - INFO: Training:: Epoch: 2/16\tBatch: 110/3125\t\tLoss: 4.384847640991211\n",
      "06/13/2021 07:07:51 AM - INFO: Training:: Epoch: 2/16\tBatch: 115/3125\t\tLoss: 4.373401641845703\n",
      "06/13/2021 07:07:58 AM - INFO: Training:: Epoch: 2/16\tBatch: 120/3125\t\tLoss: 4.0083208084106445\n",
      "06/13/2021 07:08:05 AM - INFO: Training:: Epoch: 2/16\tBatch: 125/3125\t\tLoss: 3.8693456649780273\n",
      "06/13/2021 07:08:13 AM - INFO: Training:: Epoch: 2/16\tBatch: 130/3125\t\tLoss: 4.268926620483398\n",
      "06/13/2021 07:08:20 AM - INFO: Training:: Epoch: 2/16\tBatch: 135/3125\t\tLoss: 4.205620765686035\n",
      "06/13/2021 07:08:27 AM - INFO: Training:: Epoch: 2/16\tBatch: 140/3125\t\tLoss: 4.432060718536377\n",
      "06/13/2021 07:08:34 AM - INFO: Training:: Epoch: 2/16\tBatch: 145/3125\t\tLoss: 3.915283441543579\n",
      "06/13/2021 07:08:41 AM - INFO: Training:: Epoch: 2/16\tBatch: 150/3125\t\tLoss: 4.185724258422852\n",
      "06/13/2021 07:08:48 AM - INFO: Training:: Epoch: 2/16\tBatch: 155/3125\t\tLoss: 4.0704755783081055\n",
      "06/13/2021 07:08:55 AM - INFO: Training:: Epoch: 2/16\tBatch: 160/3125\t\tLoss: 4.166600227355957\n",
      "06/13/2021 07:09:03 AM - INFO: Training:: Epoch: 2/16\tBatch: 165/3125\t\tLoss: 4.20535135269165\n",
      "06/13/2021 07:09:10 AM - INFO: Training:: Epoch: 2/16\tBatch: 170/3125\t\tLoss: 4.1173906326293945\n",
      "06/13/2021 07:09:17 AM - INFO: Training:: Epoch: 2/16\tBatch: 175/3125\t\tLoss: 4.115633010864258\n",
      "06/13/2021 07:09:24 AM - INFO: Training:: Epoch: 2/16\tBatch: 180/3125\t\tLoss: 4.0554704666137695\n",
      "06/13/2021 07:09:31 AM - INFO: Training:: Epoch: 2/16\tBatch: 185/3125\t\tLoss: 4.019916534423828\n",
      "06/13/2021 07:09:38 AM - INFO: Training:: Epoch: 2/16\tBatch: 190/3125\t\tLoss: 4.171717166900635\n",
      "06/13/2021 07:09:46 AM - INFO: Training:: Epoch: 2/16\tBatch: 195/3125\t\tLoss: 4.222842693328857\n",
      "06/13/2021 07:09:53 AM - INFO: Training:: Epoch: 2/16\tBatch: 200/3125\t\tLoss: 3.7667462825775146\n",
      "06/13/2021 07:10:00 AM - INFO: Training:: Epoch: 2/16\tBatch: 205/3125\t\tLoss: 4.185861110687256\n",
      "06/13/2021 07:10:07 AM - INFO: Training:: Epoch: 2/16\tBatch: 210/3125\t\tLoss: 4.13402795791626\n",
      "06/13/2021 07:10:14 AM - INFO: Training:: Epoch: 2/16\tBatch: 215/3125\t\tLoss: 4.22237491607666\n",
      "06/13/2021 07:10:21 AM - INFO: Training:: Epoch: 2/16\tBatch: 220/3125\t\tLoss: 4.679448127746582\n",
      "06/13/2021 07:10:29 AM - INFO: Training:: Epoch: 2/16\tBatch: 225/3125\t\tLoss: 4.079038619995117\n",
      "06/13/2021 07:10:36 AM - INFO: Training:: Epoch: 2/16\tBatch: 230/3125\t\tLoss: 4.251593589782715\n",
      "06/13/2021 07:10:43 AM - INFO: Training:: Epoch: 2/16\tBatch: 235/3125\t\tLoss: 4.086268424987793\n",
      "06/13/2021 07:10:50 AM - INFO: Training:: Epoch: 2/16\tBatch: 240/3125\t\tLoss: 4.193849086761475\n",
      "06/13/2021 07:10:57 AM - INFO: Training:: Epoch: 2/16\tBatch: 245/3125\t\tLoss: 3.938311815261841\n",
      "06/13/2021 07:11:04 AM - INFO: Training:: Epoch: 2/16\tBatch: 250/3125\t\tLoss: 4.1576948165893555\n",
      "06/13/2021 07:11:11 AM - INFO: Training:: Epoch: 2/16\tBatch: 255/3125\t\tLoss: 3.9920880794525146\n",
      "06/13/2021 07:11:19 AM - INFO: Training:: Epoch: 2/16\tBatch: 260/3125\t\tLoss: 4.198631286621094\n",
      "06/13/2021 07:11:26 AM - INFO: Training:: Epoch: 2/16\tBatch: 265/3125\t\tLoss: 3.558502197265625\n",
      "06/13/2021 07:11:33 AM - INFO: Training:: Epoch: 2/16\tBatch: 270/3125\t\tLoss: 4.255466461181641\n",
      "06/13/2021 07:11:40 AM - INFO: Training:: Epoch: 2/16\tBatch: 275/3125\t\tLoss: 4.393877029418945\n",
      "06/13/2021 07:11:47 AM - INFO: Training:: Epoch: 2/16\tBatch: 280/3125\t\tLoss: 4.264947891235352\n",
      "06/13/2021 07:11:54 AM - INFO: Training:: Epoch: 2/16\tBatch: 285/3125\t\tLoss: 4.092886447906494\n",
      "06/13/2021 07:12:01 AM - INFO: Training:: Epoch: 2/16\tBatch: 290/3125\t\tLoss: 4.23865270614624\n",
      "06/13/2021 07:12:09 AM - INFO: Training:: Epoch: 2/16\tBatch: 295/3125\t\tLoss: 3.769803524017334\n",
      "06/13/2021 07:12:16 AM - INFO: Training:: Epoch: 2/16\tBatch: 300/3125\t\tLoss: 4.049971580505371\n",
      "06/13/2021 07:12:23 AM - INFO: Training:: Epoch: 2/16\tBatch: 305/3125\t\tLoss: 4.042675971984863\n",
      "06/13/2021 07:12:30 AM - INFO: Training:: Epoch: 2/16\tBatch: 310/3125\t\tLoss: 4.236600875854492\n",
      "06/13/2021 07:12:37 AM - INFO: Training:: Epoch: 2/16\tBatch: 315/3125\t\tLoss: 4.074222087860107\n",
      "06/13/2021 07:12:44 AM - INFO: Training:: Epoch: 2/16\tBatch: 320/3125\t\tLoss: 3.685073137283325\n",
      "06/13/2021 07:12:51 AM - INFO: Training:: Epoch: 2/16\tBatch: 325/3125\t\tLoss: 4.104334354400635\n",
      "06/13/2021 07:12:59 AM - INFO: Training:: Epoch: 2/16\tBatch: 330/3125\t\tLoss: 3.8074989318847656\n",
      "06/13/2021 07:13:06 AM - INFO: Training:: Epoch: 2/16\tBatch: 335/3125\t\tLoss: 4.0953779220581055\n",
      "06/13/2021 07:13:13 AM - INFO: Training:: Epoch: 2/16\tBatch: 340/3125\t\tLoss: 3.989053249359131\n",
      "06/13/2021 07:13:20 AM - INFO: Training:: Epoch: 2/16\tBatch: 345/3125\t\tLoss: 4.0757293701171875\n",
      "06/13/2021 07:13:27 AM - INFO: Training:: Epoch: 2/16\tBatch: 350/3125\t\tLoss: 4.1815996170043945\n",
      "06/13/2021 07:13:34 AM - INFO: Training:: Epoch: 2/16\tBatch: 355/3125\t\tLoss: 4.3530073165893555\n",
      "06/13/2021 07:13:42 AM - INFO: Training:: Epoch: 2/16\tBatch: 360/3125\t\tLoss: 3.8280818462371826\n",
      "06/13/2021 07:13:49 AM - INFO: Training:: Epoch: 2/16\tBatch: 365/3125\t\tLoss: 3.7565481662750244\n",
      "06/13/2021 07:13:56 AM - INFO: Training:: Epoch: 2/16\tBatch: 370/3125\t\tLoss: 4.056674480438232\n",
      "06/13/2021 07:14:03 AM - INFO: Training:: Epoch: 2/16\tBatch: 375/3125\t\tLoss: 4.285550594329834\n",
      "06/13/2021 07:14:10 AM - INFO: Training:: Epoch: 2/16\tBatch: 380/3125\t\tLoss: 4.047940731048584\n",
      "06/13/2021 07:14:17 AM - INFO: Training:: Epoch: 2/16\tBatch: 385/3125\t\tLoss: 4.396560192108154\n",
      "06/13/2021 07:14:24 AM - INFO: Training:: Epoch: 2/16\tBatch: 390/3125\t\tLoss: 4.212149143218994\n",
      "06/13/2021 07:14:32 AM - INFO: Training:: Epoch: 2/16\tBatch: 395/3125\t\tLoss: 4.034483909606934\n",
      "06/13/2021 07:14:39 AM - INFO: Training:: Epoch: 2/16\tBatch: 400/3125\t\tLoss: 3.855968952178955\n",
      "06/13/2021 07:14:46 AM - INFO: Training:: Epoch: 2/16\tBatch: 405/3125\t\tLoss: 4.346055030822754\n",
      "06/13/2021 07:14:53 AM - INFO: Training:: Epoch: 2/16\tBatch: 410/3125\t\tLoss: 4.188499927520752\n",
      "06/13/2021 07:15:00 AM - INFO: Training:: Epoch: 2/16\tBatch: 415/3125\t\tLoss: 4.279693603515625\n",
      "06/13/2021 07:15:07 AM - INFO: Training:: Epoch: 2/16\tBatch: 420/3125\t\tLoss: 3.699808120727539\n",
      "06/13/2021 07:15:15 AM - INFO: Training:: Epoch: 2/16\tBatch: 425/3125\t\tLoss: 4.540583610534668\n",
      "06/13/2021 07:15:22 AM - INFO: Training:: Epoch: 2/16\tBatch: 430/3125\t\tLoss: 3.9064536094665527\n",
      "06/13/2021 07:15:29 AM - INFO: Training:: Epoch: 2/16\tBatch: 435/3125\t\tLoss: 3.8737807273864746\n",
      "06/13/2021 07:15:36 AM - INFO: Training:: Epoch: 2/16\tBatch: 440/3125\t\tLoss: 3.6498706340789795\n",
      "06/13/2021 07:15:43 AM - INFO: Training:: Epoch: 2/16\tBatch: 445/3125\t\tLoss: 3.8652851581573486\n",
      "06/13/2021 07:15:50 AM - INFO: Training:: Epoch: 2/16\tBatch: 450/3125\t\tLoss: 3.97501277923584\n",
      "06/13/2021 07:15:57 AM - INFO: Training:: Epoch: 2/16\tBatch: 455/3125\t\tLoss: 3.974991798400879\n",
      "06/13/2021 07:16:05 AM - INFO: Training:: Epoch: 2/16\tBatch: 460/3125\t\tLoss: 3.974431037902832\n",
      "06/13/2021 07:16:12 AM - INFO: Training:: Epoch: 2/16\tBatch: 465/3125\t\tLoss: 4.030689716339111\n",
      "06/13/2021 07:16:19 AM - INFO: Training:: Epoch: 2/16\tBatch: 470/3125\t\tLoss: 3.7901675701141357\n",
      "06/13/2021 07:16:26 AM - INFO: Training:: Epoch: 2/16\tBatch: 475/3125\t\tLoss: 4.760986804962158\n",
      "06/13/2021 07:16:33 AM - INFO: Training:: Epoch: 2/16\tBatch: 480/3125\t\tLoss: 3.6709039211273193\n",
      "06/13/2021 07:16:40 AM - INFO: Training:: Epoch: 2/16\tBatch: 485/3125\t\tLoss: 3.4651873111724854\n",
      "06/13/2021 07:16:47 AM - INFO: Training:: Epoch: 2/16\tBatch: 490/3125\t\tLoss: 4.011460781097412\n",
      "06/13/2021 07:16:55 AM - INFO: Training:: Epoch: 2/16\tBatch: 495/3125\t\tLoss: 3.939523220062256\n",
      "06/13/2021 07:17:02 AM - INFO: Training:: Epoch: 2/16\tBatch: 500/3125\t\tLoss: 4.398553848266602\n",
      "06/13/2021 07:17:09 AM - INFO: Training:: Epoch: 2/16\tBatch: 505/3125\t\tLoss: 4.199436187744141\n",
      "06/13/2021 07:17:16 AM - INFO: Training:: Epoch: 2/16\tBatch: 510/3125\t\tLoss: 3.851797103881836\n",
      "06/13/2021 07:17:23 AM - INFO: Training:: Epoch: 2/16\tBatch: 515/3125\t\tLoss: 3.5382494926452637\n",
      "06/13/2021 07:17:31 AM - INFO: Training:: Epoch: 2/16\tBatch: 520/3125\t\tLoss: 4.2216410636901855\n",
      "06/13/2021 07:17:38 AM - INFO: Training:: Epoch: 2/16\tBatch: 525/3125\t\tLoss: 4.15282678604126\n",
      "06/13/2021 07:17:45 AM - INFO: Training:: Epoch: 2/16\tBatch: 530/3125\t\tLoss: 4.351284980773926\n",
      "06/13/2021 07:17:52 AM - INFO: Training:: Epoch: 2/16\tBatch: 535/3125\t\tLoss: 4.233996868133545\n",
      "06/13/2021 07:17:59 AM - INFO: Training:: Epoch: 2/16\tBatch: 540/3125\t\tLoss: 4.203678131103516\n",
      "06/13/2021 07:18:06 AM - INFO: Training:: Epoch: 2/16\tBatch: 545/3125\t\tLoss: 4.001026153564453\n",
      "06/13/2021 07:18:13 AM - INFO: Training:: Epoch: 2/16\tBatch: 550/3125\t\tLoss: 4.025828838348389\n",
      "06/13/2021 07:18:21 AM - INFO: Training:: Epoch: 2/16\tBatch: 555/3125\t\tLoss: 4.089206695556641\n",
      "06/13/2021 07:18:28 AM - INFO: Training:: Epoch: 2/16\tBatch: 560/3125\t\tLoss: 4.161427021026611\n",
      "06/13/2021 07:18:35 AM - INFO: Training:: Epoch: 2/16\tBatch: 565/3125\t\tLoss: 4.070852279663086\n",
      "06/13/2021 07:18:42 AM - INFO: Training:: Epoch: 2/16\tBatch: 570/3125\t\tLoss: 4.2033843994140625\n",
      "06/13/2021 07:18:49 AM - INFO: Training:: Epoch: 2/16\tBatch: 575/3125\t\tLoss: 3.9502241611480713\n",
      "06/13/2021 07:18:56 AM - INFO: Training:: Epoch: 2/16\tBatch: 580/3125\t\tLoss: 4.876540660858154\n",
      "06/13/2021 07:19:03 AM - INFO: Training:: Epoch: 2/16\tBatch: 585/3125\t\tLoss: 4.05910587310791\n",
      "06/13/2021 07:19:11 AM - INFO: Training:: Epoch: 2/16\tBatch: 590/3125\t\tLoss: 4.360995292663574\n",
      "06/13/2021 07:19:18 AM - INFO: Training:: Epoch: 2/16\tBatch: 595/3125\t\tLoss: 4.154808044433594\n",
      "06/13/2021 07:19:25 AM - INFO: Training:: Epoch: 2/16\tBatch: 600/3125\t\tLoss: 4.029932022094727\n",
      "06/13/2021 07:19:32 AM - INFO: Training:: Epoch: 2/16\tBatch: 605/3125\t\tLoss: 4.06450080871582\n",
      "06/13/2021 07:19:39 AM - INFO: Training:: Epoch: 2/16\tBatch: 610/3125\t\tLoss: 4.06321907043457\n",
      "06/13/2021 07:19:46 AM - INFO: Training:: Epoch: 2/16\tBatch: 615/3125\t\tLoss: 4.172885894775391\n",
      "06/13/2021 07:19:54 AM - INFO: Training:: Epoch: 2/16\tBatch: 620/3125\t\tLoss: 3.751185894012451\n",
      "06/13/2021 07:20:01 AM - INFO: Training:: Epoch: 2/16\tBatch: 625/3125\t\tLoss: 4.297140121459961\n",
      "06/13/2021 07:20:08 AM - INFO: Training:: Epoch: 2/16\tBatch: 630/3125\t\tLoss: 4.09764289855957\n",
      "06/13/2021 07:20:15 AM - INFO: Training:: Epoch: 2/16\tBatch: 635/3125\t\tLoss: 3.578906536102295\n",
      "06/13/2021 07:20:22 AM - INFO: Training:: Epoch: 2/16\tBatch: 640/3125\t\tLoss: 4.38026762008667\n",
      "06/13/2021 07:20:29 AM - INFO: Training:: Epoch: 2/16\tBatch: 645/3125\t\tLoss: 4.019568920135498\n",
      "06/13/2021 07:20:36 AM - INFO: Training:: Epoch: 2/16\tBatch: 650/3125\t\tLoss: 4.0171356201171875\n",
      "06/13/2021 07:20:44 AM - INFO: Training:: Epoch: 2/16\tBatch: 655/3125\t\tLoss: 4.386106967926025\n",
      "06/13/2021 07:20:51 AM - INFO: Training:: Epoch: 2/16\tBatch: 660/3125\t\tLoss: 4.321990013122559\n",
      "06/13/2021 07:20:58 AM - INFO: Training:: Epoch: 2/16\tBatch: 665/3125\t\tLoss: 4.090506076812744\n",
      "06/13/2021 07:21:05 AM - INFO: Training:: Epoch: 2/16\tBatch: 670/3125\t\tLoss: 3.6967873573303223\n",
      "06/13/2021 07:21:12 AM - INFO: Training:: Epoch: 2/16\tBatch: 675/3125\t\tLoss: 3.9531173706054688\n",
      "06/13/2021 07:21:19 AM - INFO: Training:: Epoch: 2/16\tBatch: 680/3125\t\tLoss: 4.104325771331787\n",
      "06/13/2021 07:21:26 AM - INFO: Training:: Epoch: 2/16\tBatch: 685/3125\t\tLoss: 3.972766160964966\n",
      "06/13/2021 07:21:34 AM - INFO: Training:: Epoch: 2/16\tBatch: 690/3125\t\tLoss: 4.186544418334961\n",
      "06/13/2021 07:21:41 AM - INFO: Training:: Epoch: 2/16\tBatch: 695/3125\t\tLoss: 4.23450231552124\n",
      "06/13/2021 07:21:48 AM - INFO: Training:: Epoch: 2/16\tBatch: 700/3125\t\tLoss: 4.34527587890625\n",
      "06/13/2021 07:21:55 AM - INFO: Training:: Epoch: 2/16\tBatch: 705/3125\t\tLoss: 4.53333854675293\n",
      "06/13/2021 07:22:02 AM - INFO: Training:: Epoch: 2/16\tBatch: 710/3125\t\tLoss: 3.982518196105957\n",
      "06/13/2021 07:22:09 AM - INFO: Training:: Epoch: 2/16\tBatch: 715/3125\t\tLoss: 3.832312822341919\n",
      "06/13/2021 07:22:16 AM - INFO: Training:: Epoch: 2/16\tBatch: 720/3125\t\tLoss: 3.989935874938965\n",
      "06/13/2021 07:22:24 AM - INFO: Training:: Epoch: 2/16\tBatch: 725/3125\t\tLoss: 4.009881973266602\n",
      "06/13/2021 07:22:31 AM - INFO: Training:: Epoch: 2/16\tBatch: 730/3125\t\tLoss: 4.237734794616699\n",
      "06/13/2021 07:22:38 AM - INFO: Training:: Epoch: 2/16\tBatch: 735/3125\t\tLoss: 4.0922770500183105\n",
      "06/13/2021 07:22:45 AM - INFO: Training:: Epoch: 2/16\tBatch: 740/3125\t\tLoss: 4.035762786865234\n",
      "06/13/2021 07:22:52 AM - INFO: Training:: Epoch: 2/16\tBatch: 745/3125\t\tLoss: 4.187434673309326\n",
      "06/13/2021 07:22:59 AM - INFO: Training:: Epoch: 2/16\tBatch: 750/3125\t\tLoss: 4.023257255554199\n",
      "06/13/2021 07:23:06 AM - INFO: Training:: Epoch: 2/16\tBatch: 755/3125\t\tLoss: 3.927824020385742\n",
      "06/13/2021 07:23:14 AM - INFO: Training:: Epoch: 2/16\tBatch: 760/3125\t\tLoss: 3.7000129222869873\n",
      "06/13/2021 07:23:21 AM - INFO: Training:: Epoch: 2/16\tBatch: 765/3125\t\tLoss: 4.221566677093506\n",
      "06/13/2021 07:23:28 AM - INFO: Training:: Epoch: 2/16\tBatch: 770/3125\t\tLoss: 4.065019130706787\n",
      "06/13/2021 07:23:35 AM - INFO: Training:: Epoch: 2/16\tBatch: 775/3125\t\tLoss: 4.302906513214111\n",
      "06/13/2021 07:23:42 AM - INFO: Training:: Epoch: 2/16\tBatch: 780/3125\t\tLoss: 3.9095866680145264\n",
      "06/13/2021 07:23:49 AM - INFO: Training:: Epoch: 2/16\tBatch: 785/3125\t\tLoss: 3.706204891204834\n",
      "06/13/2021 07:23:57 AM - INFO: Training:: Epoch: 2/16\tBatch: 790/3125\t\tLoss: 3.6609134674072266\n",
      "06/13/2021 07:24:04 AM - INFO: Training:: Epoch: 2/16\tBatch: 795/3125\t\tLoss: 3.875574827194214\n",
      "06/13/2021 07:24:11 AM - INFO: Training:: Epoch: 2/16\tBatch: 800/3125\t\tLoss: 4.13615083694458\n",
      "06/13/2021 07:24:18 AM - INFO: Training:: Epoch: 2/16\tBatch: 805/3125\t\tLoss: 3.819727659225464\n",
      "06/13/2021 07:24:25 AM - INFO: Training:: Epoch: 2/16\tBatch: 810/3125\t\tLoss: 4.2753472328186035\n",
      "06/13/2021 07:24:32 AM - INFO: Training:: Epoch: 2/16\tBatch: 815/3125\t\tLoss: 3.848243474960327\n",
      "06/13/2021 07:24:39 AM - INFO: Training:: Epoch: 2/16\tBatch: 820/3125\t\tLoss: 3.980165958404541\n",
      "06/13/2021 07:24:47 AM - INFO: Training:: Epoch: 2/16\tBatch: 825/3125\t\tLoss: 4.24174690246582\n",
      "06/13/2021 07:24:54 AM - INFO: Training:: Epoch: 2/16\tBatch: 830/3125\t\tLoss: 3.8473734855651855\n",
      "06/13/2021 07:25:01 AM - INFO: Training:: Epoch: 2/16\tBatch: 835/3125\t\tLoss: 3.956757068634033\n",
      "06/13/2021 07:25:08 AM - INFO: Training:: Epoch: 2/16\tBatch: 840/3125\t\tLoss: 3.658102035522461\n",
      "06/13/2021 07:25:15 AM - INFO: Training:: Epoch: 2/16\tBatch: 845/3125\t\tLoss: 3.683948278427124\n",
      "06/13/2021 07:25:22 AM - INFO: Training:: Epoch: 2/16\tBatch: 850/3125\t\tLoss: 4.467824935913086\n",
      "06/13/2021 07:25:29 AM - INFO: Training:: Epoch: 2/16\tBatch: 855/3125\t\tLoss: 4.07614803314209\n",
      "06/13/2021 07:25:37 AM - INFO: Training:: Epoch: 2/16\tBatch: 860/3125\t\tLoss: 4.056482791900635\n",
      "06/13/2021 07:25:44 AM - INFO: Training:: Epoch: 2/16\tBatch: 865/3125\t\tLoss: 3.6494367122650146\n",
      "06/13/2021 07:25:51 AM - INFO: Training:: Epoch: 2/16\tBatch: 870/3125\t\tLoss: 3.475896120071411\n",
      "06/13/2021 07:25:58 AM - INFO: Training:: Epoch: 2/16\tBatch: 875/3125\t\tLoss: 4.487396717071533\n",
      "06/13/2021 07:26:05 AM - INFO: Training:: Epoch: 2/16\tBatch: 880/3125\t\tLoss: 4.1788105964660645\n",
      "06/13/2021 07:26:12 AM - INFO: Training:: Epoch: 2/16\tBatch: 885/3125\t\tLoss: 3.988689661026001\n",
      "06/13/2021 07:26:20 AM - INFO: Training:: Epoch: 2/16\tBatch: 890/3125\t\tLoss: 3.8581385612487793\n",
      "06/13/2021 07:26:27 AM - INFO: Training:: Epoch: 2/16\tBatch: 895/3125\t\tLoss: 4.17296028137207\n",
      "06/13/2021 07:26:34 AM - INFO: Training:: Epoch: 2/16\tBatch: 900/3125\t\tLoss: 4.120193004608154\n",
      "06/13/2021 07:26:41 AM - INFO: Training:: Epoch: 2/16\tBatch: 905/3125\t\tLoss: 4.003020286560059\n",
      "06/13/2021 07:26:48 AM - INFO: Training:: Epoch: 2/16\tBatch: 910/3125\t\tLoss: 3.7491636276245117\n",
      "06/13/2021 07:26:55 AM - INFO: Training:: Epoch: 2/16\tBatch: 915/3125\t\tLoss: 4.131000518798828\n",
      "06/13/2021 07:27:02 AM - INFO: Training:: Epoch: 2/16\tBatch: 920/3125\t\tLoss: 4.2655487060546875\n",
      "06/13/2021 07:27:10 AM - INFO: Training:: Epoch: 2/16\tBatch: 925/3125\t\tLoss: 4.00445556640625\n",
      "06/13/2021 07:27:17 AM - INFO: Training:: Epoch: 2/16\tBatch: 930/3125\t\tLoss: 3.79131817817688\n",
      "06/13/2021 07:27:24 AM - INFO: Training:: Epoch: 2/16\tBatch: 935/3125\t\tLoss: 4.388314247131348\n",
      "06/13/2021 07:27:31 AM - INFO: Training:: Epoch: 2/16\tBatch: 940/3125\t\tLoss: 4.1012349128723145\n",
      "06/13/2021 07:27:38 AM - INFO: Training:: Epoch: 2/16\tBatch: 945/3125\t\tLoss: 3.950669288635254\n",
      "06/13/2021 07:27:45 AM - INFO: Training:: Epoch: 2/16\tBatch: 950/3125\t\tLoss: 4.356925964355469\n",
      "06/13/2021 07:27:53 AM - INFO: Training:: Epoch: 2/16\tBatch: 955/3125\t\tLoss: 4.111488342285156\n",
      "06/13/2021 07:28:00 AM - INFO: Training:: Epoch: 2/16\tBatch: 960/3125\t\tLoss: 3.7624287605285645\n",
      "06/13/2021 07:28:07 AM - INFO: Training:: Epoch: 2/16\tBatch: 965/3125\t\tLoss: 3.7313458919525146\n",
      "06/13/2021 07:28:14 AM - INFO: Training:: Epoch: 2/16\tBatch: 970/3125\t\tLoss: 4.078999996185303\n",
      "06/13/2021 07:28:21 AM - INFO: Training:: Epoch: 2/16\tBatch: 975/3125\t\tLoss: 3.3783185482025146\n",
      "06/13/2021 07:28:28 AM - INFO: Training:: Epoch: 2/16\tBatch: 980/3125\t\tLoss: 4.425507545471191\n",
      "06/13/2021 07:28:35 AM - INFO: Training:: Epoch: 2/16\tBatch: 985/3125\t\tLoss: 3.96828031539917\n",
      "06/13/2021 07:28:43 AM - INFO: Training:: Epoch: 2/16\tBatch: 990/3125\t\tLoss: 3.9012115001678467\n",
      "06/13/2021 07:28:50 AM - INFO: Training:: Epoch: 2/16\tBatch: 995/3125\t\tLoss: 3.940556049346924\n",
      "06/13/2021 07:28:57 AM - INFO: Training:: Epoch: 2/16\tBatch: 1000/3125\t\tLoss: 4.2035369873046875\n",
      "06/13/2021 07:29:04 AM - INFO: Training:: Epoch: 2/16\tBatch: 1005/3125\t\tLoss: 4.259525775909424\n",
      "06/13/2021 07:29:11 AM - INFO: Training:: Epoch: 2/16\tBatch: 1010/3125\t\tLoss: 4.2385053634643555\n",
      "06/13/2021 07:29:18 AM - INFO: Training:: Epoch: 2/16\tBatch: 1015/3125\t\tLoss: 3.6545748710632324\n",
      "06/13/2021 07:29:26 AM - INFO: Training:: Epoch: 2/16\tBatch: 1020/3125\t\tLoss: 4.713476181030273\n",
      "06/13/2021 07:29:33 AM - INFO: Training:: Epoch: 2/16\tBatch: 1025/3125\t\tLoss: 4.1402907371521\n",
      "06/13/2021 07:29:40 AM - INFO: Training:: Epoch: 2/16\tBatch: 1030/3125\t\tLoss: 3.9622068405151367\n",
      "06/13/2021 07:29:47 AM - INFO: Training:: Epoch: 2/16\tBatch: 1035/3125\t\tLoss: 3.776486396789551\n",
      "06/13/2021 07:29:54 AM - INFO: Training:: Epoch: 2/16\tBatch: 1040/3125\t\tLoss: 3.408252239227295\n",
      "06/13/2021 07:30:01 AM - INFO: Training:: Epoch: 2/16\tBatch: 1045/3125\t\tLoss: 4.063061714172363\n",
      "06/13/2021 07:30:08 AM - INFO: Training:: Epoch: 2/16\tBatch: 1050/3125\t\tLoss: 4.16390323638916\n",
      "06/13/2021 07:30:16 AM - INFO: Training:: Epoch: 2/16\tBatch: 1055/3125\t\tLoss: 3.746053457260132\n",
      "06/13/2021 07:30:23 AM - INFO: Training:: Epoch: 2/16\tBatch: 1060/3125\t\tLoss: 3.756560802459717\n",
      "06/13/2021 07:30:30 AM - INFO: Training:: Epoch: 2/16\tBatch: 1065/3125\t\tLoss: 4.177567005157471\n",
      "06/13/2021 07:30:37 AM - INFO: Training:: Epoch: 2/16\tBatch: 1070/3125\t\tLoss: 4.207738399505615\n",
      "06/13/2021 07:30:44 AM - INFO: Training:: Epoch: 2/16\tBatch: 1075/3125\t\tLoss: 4.0852274894714355\n",
      "06/13/2021 07:30:51 AM - INFO: Training:: Epoch: 2/16\tBatch: 1080/3125\t\tLoss: 4.263452529907227\n",
      "06/13/2021 07:30:58 AM - INFO: Training:: Epoch: 2/16\tBatch: 1085/3125\t\tLoss: 4.203205108642578\n",
      "06/13/2021 07:31:06 AM - INFO: Training:: Epoch: 2/16\tBatch: 1090/3125\t\tLoss: 4.05391263961792\n",
      "06/13/2021 07:31:13 AM - INFO: Training:: Epoch: 2/16\tBatch: 1095/3125\t\tLoss: 4.43240213394165\n",
      "06/13/2021 07:31:20 AM - INFO: Training:: Epoch: 2/16\tBatch: 1100/3125\t\tLoss: 3.7829580307006836\n",
      "06/13/2021 07:31:27 AM - INFO: Training:: Epoch: 2/16\tBatch: 1105/3125\t\tLoss: 4.22580623626709\n",
      "06/13/2021 07:31:34 AM - INFO: Training:: Epoch: 2/16\tBatch: 1110/3125\t\tLoss: 3.985884666442871\n",
      "06/13/2021 07:31:41 AM - INFO: Training:: Epoch: 2/16\tBatch: 1115/3125\t\tLoss: 4.02444314956665\n",
      "06/13/2021 07:31:49 AM - INFO: Training:: Epoch: 2/16\tBatch: 1120/3125\t\tLoss: 4.243927955627441\n",
      "06/13/2021 07:31:56 AM - INFO: Training:: Epoch: 2/16\tBatch: 1125/3125\t\tLoss: 4.043397903442383\n",
      "06/13/2021 07:32:03 AM - INFO: Training:: Epoch: 2/16\tBatch: 1130/3125\t\tLoss: 4.09013557434082\n",
      "06/13/2021 07:32:10 AM - INFO: Training:: Epoch: 2/16\tBatch: 1135/3125\t\tLoss: 4.160267353057861\n",
      "06/13/2021 07:32:17 AM - INFO: Training:: Epoch: 2/16\tBatch: 1140/3125\t\tLoss: 3.7725024223327637\n",
      "06/13/2021 07:32:24 AM - INFO: Training:: Epoch: 2/16\tBatch: 1145/3125\t\tLoss: 3.6167008876800537\n",
      "06/13/2021 07:32:32 AM - INFO: Training:: Epoch: 2/16\tBatch: 1150/3125\t\tLoss: 3.8870222568511963\n",
      "06/13/2021 07:32:39 AM - INFO: Training:: Epoch: 2/16\tBatch: 1155/3125\t\tLoss: 4.383725643157959\n",
      "06/13/2021 07:32:46 AM - INFO: Training:: Epoch: 2/16\tBatch: 1160/3125\t\tLoss: 4.152229309082031\n",
      "06/13/2021 07:32:53 AM - INFO: Training:: Epoch: 2/16\tBatch: 1165/3125\t\tLoss: 3.6596343517303467\n",
      "06/13/2021 07:33:00 AM - INFO: Training:: Epoch: 2/16\tBatch: 1170/3125\t\tLoss: 4.10282564163208\n",
      "06/13/2021 07:33:07 AM - INFO: Training:: Epoch: 2/16\tBatch: 1175/3125\t\tLoss: 3.6053507328033447\n",
      "06/13/2021 07:33:14 AM - INFO: Training:: Epoch: 2/16\tBatch: 1180/3125\t\tLoss: 4.001183032989502\n",
      "06/13/2021 07:33:22 AM - INFO: Training:: Epoch: 2/16\tBatch: 1185/3125\t\tLoss: 4.348482131958008\n",
      "06/13/2021 07:33:29 AM - INFO: Training:: Epoch: 2/16\tBatch: 1190/3125\t\tLoss: 3.8808341026306152\n",
      "06/13/2021 07:33:36 AM - INFO: Training:: Epoch: 2/16\tBatch: 1195/3125\t\tLoss: 3.8112268447875977\n",
      "06/13/2021 07:33:43 AM - INFO: Training:: Epoch: 2/16\tBatch: 1200/3125\t\tLoss: 4.355874061584473\n",
      "06/13/2021 07:33:50 AM - INFO: Training:: Epoch: 2/16\tBatch: 1205/3125\t\tLoss: 3.9965295791625977\n",
      "06/13/2021 07:33:57 AM - INFO: Training:: Epoch: 2/16\tBatch: 1210/3125\t\tLoss: 4.220462322235107\n",
      "06/13/2021 07:34:04 AM - INFO: Training:: Epoch: 2/16\tBatch: 1215/3125\t\tLoss: 4.089663982391357\n",
      "06/13/2021 07:34:12 AM - INFO: Training:: Epoch: 2/16\tBatch: 1220/3125\t\tLoss: 4.15728759765625\n",
      "06/13/2021 07:34:19 AM - INFO: Training:: Epoch: 2/16\tBatch: 1225/3125\t\tLoss: 3.277862787246704\n",
      "06/13/2021 07:34:26 AM - INFO: Training:: Epoch: 2/16\tBatch: 1230/3125\t\tLoss: 3.535386562347412\n",
      "06/13/2021 07:34:33 AM - INFO: Training:: Epoch: 2/16\tBatch: 1235/3125\t\tLoss: 3.295511245727539\n",
      "06/13/2021 07:34:40 AM - INFO: Training:: Epoch: 2/16\tBatch: 1240/3125\t\tLoss: 4.041378021240234\n",
      "06/13/2021 07:34:47 AM - INFO: Training:: Epoch: 2/16\tBatch: 1245/3125\t\tLoss: 3.9697425365448\n",
      "06/13/2021 07:34:54 AM - INFO: Training:: Epoch: 2/16\tBatch: 1250/3125\t\tLoss: 4.380613327026367\n",
      "06/13/2021 07:35:02 AM - INFO: Training:: Epoch: 2/16\tBatch: 1255/3125\t\tLoss: 3.668715476989746\n",
      "06/13/2021 07:35:09 AM - INFO: Training:: Epoch: 2/16\tBatch: 1260/3125\t\tLoss: 3.9885897636413574\n",
      "06/13/2021 07:35:16 AM - INFO: Training:: Epoch: 2/16\tBatch: 1265/3125\t\tLoss: 4.3025970458984375\n",
      "06/13/2021 07:35:23 AM - INFO: Training:: Epoch: 2/16\tBatch: 1270/3125\t\tLoss: 3.7099626064300537\n",
      "06/13/2021 07:35:30 AM - INFO: Training:: Epoch: 2/16\tBatch: 1275/3125\t\tLoss: 4.119059085845947\n",
      "06/13/2021 07:35:37 AM - INFO: Training:: Epoch: 2/16\tBatch: 1280/3125\t\tLoss: 3.973747491836548\n",
      "06/13/2021 07:35:45 AM - INFO: Training:: Epoch: 2/16\tBatch: 1285/3125\t\tLoss: 3.533249616622925\n",
      "06/13/2021 07:35:52 AM - INFO: Training:: Epoch: 2/16\tBatch: 1290/3125\t\tLoss: 3.753462553024292\n",
      "06/13/2021 07:35:59 AM - INFO: Training:: Epoch: 2/16\tBatch: 1295/3125\t\tLoss: 4.170858383178711\n",
      "06/13/2021 07:36:06 AM - INFO: Training:: Epoch: 2/16\tBatch: 1300/3125\t\tLoss: 4.455733776092529\n",
      "06/13/2021 07:36:13 AM - INFO: Training:: Epoch: 2/16\tBatch: 1305/3125\t\tLoss: 4.226966381072998\n",
      "06/13/2021 07:36:20 AM - INFO: Training:: Epoch: 2/16\tBatch: 1310/3125\t\tLoss: 3.831245183944702\n",
      "06/13/2021 07:36:27 AM - INFO: Training:: Epoch: 2/16\tBatch: 1315/3125\t\tLoss: 4.082955360412598\n",
      "06/13/2021 07:36:35 AM - INFO: Training:: Epoch: 2/16\tBatch: 1320/3125\t\tLoss: 3.8285839557647705\n",
      "06/13/2021 07:36:42 AM - INFO: Training:: Epoch: 2/16\tBatch: 1325/3125\t\tLoss: 3.742851972579956\n",
      "06/13/2021 07:36:49 AM - INFO: Training:: Epoch: 2/16\tBatch: 1330/3125\t\tLoss: 3.6385536193847656\n",
      "06/13/2021 07:36:56 AM - INFO: Training:: Epoch: 2/16\tBatch: 1335/3125\t\tLoss: 3.85860276222229\n",
      "06/13/2021 07:37:03 AM - INFO: Training:: Epoch: 2/16\tBatch: 1340/3125\t\tLoss: 3.885239362716675\n",
      "06/13/2021 07:37:10 AM - INFO: Training:: Epoch: 2/16\tBatch: 1345/3125\t\tLoss: 4.046209335327148\n",
      "06/13/2021 07:37:17 AM - INFO: Training:: Epoch: 2/16\tBatch: 1350/3125\t\tLoss: 4.190951824188232\n",
      "06/13/2021 07:37:25 AM - INFO: Training:: Epoch: 2/16\tBatch: 1355/3125\t\tLoss: 4.311960220336914\n"
     ]
    }
   ],
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1622607063183
    },
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}